{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vksfdc2019/VamseeK.guthub.io/blob/main/Medical_Assistant_Problem_Statement_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CNz35ia6Bz3"
      },
      "source": [
        "# <Center> Problem Statement - Medical Assistant </Center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkRbhMJH6Bz3"
      },
      "source": [
        "### Business Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PBm5xaj6Bz3"
      },
      "source": [
        "The healthcare industry is rapidly evolving, with professionals facing increasing challenges in managing vast volumes of medical data while delivering accurate and timely diagnoses. The need for quick access to comprehensive, reliable, and up-to-date medical knowledge is critical for improving patient outcomes and ensuring informed decision-making in a fast-paced environment.\n",
        "\n",
        "Healthcare professionals often encounter information overload, struggling to sift through extensive research and data to create accurate diagnoses and treatment plans. This challenge is amplified by the need for efficiency, particularly in emergencies, where time-sensitive decisions are vital. Furthermore, access to trusted, current medical information from renowned manuals and research papers is essential for maintaining high standards of care.\n",
        "\n",
        "To address these challenges, healthcare centers can focus on integrating systems that streamline access to medical knowledge, provide tools to support quick decision-making, and enhance efficiency. Leveraging centralized knowledge platforms and ensuring healthcare providers have continuous access to reliable resources can significantly improve patient care and operational effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xDPsqvO6Bz5"
      },
      "source": [
        "**Common Questions to Answer**\n",
        "\n",
        "**1. Diagnostic Assistance**: \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
        "\n",
        "**2. Drug Information**: \"Can you provide the trade names of medications used for treating hypertension?\"\n",
        "\n",
        "**3. Treatment Plans**: \"What are the first-line options and alternatives for managing rheumatoid arthritis?\"\n",
        "\n",
        "**4. Specialty Knowledge**: \"What are the diagnostic steps for suspected endocrine disorders?\"\n",
        "\n",
        "**5. Critical Care Protocols**: \"What is the protocol for managing sepsis in a critical care unit?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CARPKFwm6Bz4"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOElOEXq6Bz4"
      },
      "source": [
        "As an AI specialist, your task is to develop a RAG-based AI solution using renowned medical manuals to address healthcare challenges. The objective is to **understand** issues like information overload, **apply** AI techniques to streamline decision-making, **analyze** its impact on diagnostics and patient outcomes, **evaluate** its potential to standardize care practices, and **create** a functional prototype demonstrating its feasibility and effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by9EvAnkSpZf"
      },
      "source": [
        "### Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw5LievCSru2"
      },
      "source": [
        "The **Merck Manuals** are medical references published by the American pharmaceutical company Merck & Co., that cover a wide range of medical topics, including disorders, tests, diagnoses, and drugs. The manuals have been published since 1899, when Merck & Co. was still a subsidiary of the German company Merck.\n",
        "\n",
        "The manual is provided as a PDF with over 4,000 pages divided into 23 sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnwETBOE6Bz5"
      },
      "source": [
        "## Installing and Importing Necessary Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing llama-cpp-python"
      ],
      "metadata": {
        "id": "0k452l1g4Pl4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q4GgLhZhUM4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a00158-0a43-4f81-d544-043a08645639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m284.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m285.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m271.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m189.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Installation for GPU llama-cpp-python\n",
        "# uncomment and run the following code in case GPU is being used\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q\n",
        "\n",
        "# Installation for CPU llama-cpp-python\n",
        "# uncomment and run the following code in case GPU is not being used\n",
        "# !CMAKE_ARGS=\"-DLLAMA_CUBLAS=off\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.85 --force-reinstall --no-cache-dir -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing huggingface, pandas ticktoken and related dependencies"
      ],
      "metadata": {
        "id": "PrFuTM-_4R-i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VOckDVkWGei",
        "outputId": "d3ed6c5c-6877-4341-deb1-9716dc558608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m130.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m114.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-cloud-bigquery 3.34.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.2 which is incompatible.\n",
            "langchain-text-splitters 0.3.8 requires langchain-core<1.0.0,>=0.3.51, but you have langchain-core 0.1.23 which is incompatible.\n",
            "diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.2 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.2 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "blosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# For installing the libraries & downloading models from HF Hub\n",
        "!pip install huggingface_hub==0.23.2 pandas==1.5.3 tiktoken==0.6.0 pymupdf==1.25.1 langchain==0.1.1 langchain-community==0.0.13 chromadb==0.4.22 sentence-transformers==2.3.1 numpy==1.25.2 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uninstalling unsupported versions of the libraries and installing new supported libraries"
      ],
      "metadata": {
        "id": "1Ouqvpt74g6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall numpy and then reinstall it, forcing the correct version\n",
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.25.2 # Use the version you specified in your initial pip install\n",
        "\n",
        "# Now install all your other libraries.\n",
        "# Crucially, ensure the pandas version is compatible with this numpy version.\n",
        "# If you keep getting errors, try specifying a slightly older pandas version, e.g., 1.4.x or 1.3.x\n",
        "!pip install huggingface_hub==0.23.2 pandas==1.5.3 tiktoken==0.6.0 pymupdf==1.25.1 langchain==0.1.1 langchain-community==0.0.13 chromadb==0.4.22 sentence-transformers==2.3.1 -q\n",
        "\n",
        "# Restart your runtime after running these cells\n",
        "import os\n",
        "os.kill(os.getpid(), 9) # This will restart the Colab runtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "_uTeH0x_cRIJ",
        "outputId": "fef68800-79b6-4937-ce85-46b29f62485e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.25.2\n",
            "Uninstalling numpy-1.25.2:\n",
            "  Successfully uninstalled numpy-1.25.2\n",
            "Collecting numpy==1.25.2\n",
            "  Using cached numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.2 which is incompatible.\n",
            "diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.2 which is incompatible.\n",
            "xarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "gradio 5.31.0 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.2 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "blosc2 3.5.0 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "aad368d83bd04fc4b3968e701534d5dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display the version of numpy"
      ],
      "metadata": {
        "id": "UsTVDsqA40YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the numpy library for numerical computations\n",
        "import numpy\n",
        "\n",
        "# Print the version number of the installed numpy package\n",
        "print(numpy.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzeE0J2ecGSb",
        "outputId": "6217711b-9109-4b9b-ce70-c08761b831f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RTY9GN4oWK3g"
      },
      "outputs": [],
      "source": [
        "# Libraries for processing dataframes and text\n",
        "import json   # For handling JSON data\n",
        "import os     # For interacting with the operating system (file paths, environment variables, etc.)\n",
        "import tiktoken  # For tokenization, often used with language models\n",
        "import pandas as pd  # For working with tabular data using dataframes\n",
        "\n",
        "# Libraries for Loading Data, Chunking, Embedding, and Vector Databases\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter  # For splitting long texts into smaller chunks\n",
        "from langchain_community.document_loaders import PyMuPDFLoader  # For loading PDF documents using PyMuPDF\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings  # For creating embeddings with sentence transformers\n",
        "from langchain_community.vectorstores import Chroma  # For storing and searching embeddings in a vector store (ChromaDB)\n",
        "\n",
        "# Libraries for downloading and loading the LLM (Large Language Model)\n",
        "from huggingface_hub import hf_hub_download  # For downloading models and files from the Hugging Face Hub\n",
        "from llama_cpp import Llama  # For loading and running Llama models (GGUF format) using llama.cpp backend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtZWqj0wFTS1"
      },
      "source": [
        "## Question Answering using LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq1lhM4WFTS2"
      },
      "source": [
        "#### Downloading and Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the name of the Hugging Face Hub repository containing the model\n",
        "model_name = \"TheBloke/Llama-2-7B-Chat-GGUF\"\n",
        "\n",
        "# Specify the filename of the desired model weights file in the repo\n",
        "model_file = \"llama-2-7b-chat.Q4_K_M.gguf\"\n",
        "\n",
        "# Download the model file from the Hugging Face Hub and get the local path where it's saved\n",
        "model_path = hf_hub_download(model_name, filename=model_file)\n",
        "\n",
        "# Load the Llama language model from the specified file,\n",
        "# setting the context window to 4096 tokens and using all available GPU layers for faster inference\n",
        "llm = Llama(model_path=model_path, n_ctx=4096, n_gpu_layers=-1)"
      ],
      "metadata": {
        "id": "dA3XQMWmQLJp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "3802fcd9847a4a94bf34e14ee569deb7",
            "1ad5597d8cf14b9795d6d3032c949870",
            "0753920b3480480c99924ed365218595",
            "692b5837aaa04c1580dd4408de709e37",
            "a809e72e05124e3b8b03bc0f33914e40",
            "1bcaef1aaace405db7c572d4e673753b",
            "e2927971513240c29b1118b95550994e",
            "ad8676e6089d433bac36b44924b755f4",
            "6e86d91d945f4d308a7db0bdf4be5dcc",
            "444a920abaa341e9a972df8880e2338c",
            "7cf5f74dd9c04a7b8637a96710b07a68"
          ]
        },
        "outputId": "da43d299-327e-452d-ecfb-2a6e415db2d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-7b-chat.Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3802fcd9847a4a94bf34e14ee569deb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzzkvIXvFTS4"
      },
      "source": [
        "#### Response"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to Generate Response from Llama Language Model Based on User Prompt"
      ],
      "metadata": {
        "id": "E4_OamNGxbkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate, process, and return the response from the LLM\n",
        "def generate_llama_response(user_prompt):\n",
        "\n",
        "    # Define a system message to instruct the LLM on how to respond\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Respond to the user question based on the user prompt<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "\n",
        "    # Combine the user prompt and system message to form the full prompt for the model\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "\n",
        "    # Generate a response from the LLaMA language model with specified generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # Pass the full prompt to the model\n",
        "        max_tokens=1024,         # Set the maximum number of tokens in the output\n",
        "        temperature=0.01,        # Control randomness; lower values make output more deterministic\n",
        "        top_p=0.95,              # Nucleus sampling parameter (probability mass to sample from)\n",
        "        repeat_penalty=1.2,      # Penalize repeated phrases in the output\n",
        "        top_k=50,                # Limit sampling to the top_k most probable next tokens\n",
        "        stop=['INST'],           # Stop generating when 'INST' is encountered\n",
        "        echo=False               # Do not include the prompt in the output\n",
        "    )\n",
        "\n",
        "    # Extract the generated text from the model's response dictionary\n",
        "    response_text = response[\"choices\"][0][\"text\"]\n",
        "    return response_text         # Return only the generated response text"
      ],
      "metadata": {
        "id": "GJD6mB46THY1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **`max_tokens`**: This parameter **specifies the maximum number of tokens that the model should generate** in response to the prompt.\n",
        "\n",
        "- **`temperature`**: This parameter **controls the randomness of the generated response**. A higher temperature value will result in a more random response, while a lower temperature value will result in a more predictable response.\n",
        "\n",
        "- **`top_p`**: This parameter **controls the diversity of the generated response by establishing a cumulative probability cutoff for token selection**. A higher value of top_p will result in a more diverse response, while a lower value will result in a less diverse response.\n",
        "\n",
        "- **`repeat_penalty`**: This parameter **controls the penalty for repeating tokens in the generated response**. A higher value of repeat_penalty will result in a lower probability of repeating tokens, while a lower value will result in a higher probability of repeating tokens.\n",
        "\n",
        "- **`top_k`**: This parameter **controls the maximum number of most-likely next tokens to consider** when generating the response at each step.\n",
        "\n",
        "- **`stop`**: This parameter is a **list of tokens that are used to dynamically stop response generation** whenever the tokens in the list are encountered.\n",
        "\n",
        "- **`echo`**: This parameter **controls whether the input (prompt) to the model should be returned** in the model response.\n"
      ],
      "metadata": {
        "id": "CMIQ06SmTNca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate a response from the language model using the provided query and generation parameters\n",
        "def response(query, max_tokens=128, temperature=0, top_p=0.95, top_k=50):\n",
        "    # Generate a response from the LLM using the input prompt and specified parameters\n",
        "    model_output = llm(\n",
        "        prompt=query,            # The input prompt to generate a response for\n",
        "        max_tokens=max_tokens,   # Maximum number of tokens in the generated output\n",
        "        temperature=temperature, # Controls randomness; lower values make the output more deterministic\n",
        "        top_p=top_p,             # Nucleus sampling: probability mass for candidate tokens\n",
        "        top_k=top_k              # Only consider the top_k most probable tokens at each step\n",
        "    )\n",
        "\n",
        "    # Extract and return the generated text from the model's output\n",
        "    return model_output['choices'][0]['text']"
      ],
      "metadata": {
        "id": "hG_IaZj0QLw4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question Answering using LLM"
      ],
      "metadata": {
        "id": "AOYDqah8x05y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8YgK91SFjVY"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user's question about sepsis management in a critical care unit\n",
        "user_prompt = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "\n",
        "# Generate a response from the Llama language model using the user prompt\n",
        "response = generate_llama_response(user_prompt)\n",
        "\n",
        "# Print the generated response to the console\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7abjMXlPTRRc",
        "outputId": "0861fd04-5d8f-4a70-eadb-962da60e83ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Managing sepsis in a critical care unit requires a coordinated and timely approach that includes several key steps. Here are some of the protocols for managing sepsis in a critical care unit:\n",
            "1. Early recognition and activation of sepsis protocol: The first step is to recognize the signs and symptoms of sepsis early on and activate the hospital's sepsis protocol. This typically involves notifying the attending physician, who will then initiate treatment.\n",
            "2. Administering antibiotics: Once sepsis has been confirmed, the next step is to administer broad-spectrum antibiotics effective against common causes of sepsis, such as gram-positive and gram-negative bacteria. The choice of antibiotic will depend on the suspected pathogen and the patient's medical history.\n",
            "3. Monitoring vital signs: Close monitoring of vital signs is crucial in managing sepsis. This includes tracking temperature, blood pressure, heart rate, respiratory rate, and oxygen saturation levels.\n",
            "4. Providing fluid resuscitation: Sepsis can lead to hypotension, which may require fluid resuscitation to maintain mean arterial pressure (MAP) ≥65 mmHg. The choice of fluids will depend on the patient's clinical status and any underlying medical conditions.\n",
            "5. Managing pain: Pain management is essential in sepsis patients, who are at risk for opioid-induced respiratory depression. Non-opioid analgesics such as acetaminophen or nonsteroidal anti-inflammatory drugs (NSAIDs) may be used initially, and if necessary, opioids can be added gradually while closely monitoring for signs of respiratory depression.\n",
            "6. Addressing underlying infections: Identifying and addressing any underlying infections is critical in managing sepsis. This includes cultures to identify the causative pathogen(s) and appropriate antimicrobial therapy.\n",
            "7. Monitoring for organ dysfunction: Close monitoring of vital organs, such as kidneys, liver, heart, and lungs, is necessary in sepsis patients at risk for organ failure. This includes serial measurements of serum creatinine, bilirubin, troponin, and lactate levels.\n",
            "8. Providing vasopressor support: Vasopressors may be used to manage hypotension in sepsis patients who are not responding to fluid resuscitation or have signs of cardiovascular instability. The choice of vasopressor will depend on the patient's clinical status and any underlying medical conditions.\n",
            "9. Managing hyperglycemia: Elevated blood glucose levels can exacerbate sepsis, so close monitoring and management are essential. This includes administering insulin or other anti-hyperglycemic agents as needed to maintain blood sugar levels within a normal range.\n",
            "10. Coordinating care with multidisciplinary team: Managing sepsis in a critical care unit requires coordination among various healthcare professionals, including intensivists, emergency medicine physicians, infectious disease specialists, and nurses. A multidisciplinary approach ensures that all aspects of patient care are addressed promptly and effectively.\n",
            "By following these protocols for managing sepsis in a critical care unit, healthcare providers can improve survival rates and reduce the risk of complications associated with this life-threatening condition.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments/Observations from the above response for Query 1\n",
        "- Emphasizes the importance of early recognition and rapid activation of sepsis protocols.\n",
        "- Highlights the need for prompt administration of broad-spectrum antibiotics.\n",
        "- Stresses continuous monitoring of vital signs and organ function to detect deterioration.\n",
        "- Recommends individualized fluid resuscitation and vasopressor support for hemodynamic stability.\n",
        "- Addresses pain management with a preference for non-opioid analgesics initially.\n",
        "- Underlines the necessity of identifying and treating underlying infections.\n",
        "- Suggests close management of hyperglycemia to prevent complications.\n",
        "- Advocates for a multidisciplinary team approach to ensure comprehensive patient care.\n",
        "- Overall, the protocols are evidence-based and align with current best practices for sepsis management."
      ],
      "metadata": {
        "id": "8CrTW_WBytrC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6yxICeVFjVc"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user's question about symptoms and treatment options for appendicitis\n",
        "user_prompt = \"What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?\"\n",
        "\n",
        "# Generate a response from the Llama language model using the defined user prompt\n",
        "response = generate_llama_response(user_prompt)\n",
        "\n",
        "# Print the generated response to the console\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iQcoX_FTziX",
        "outputId": "5d10abad-b1a9-4dcb-ce1d-9b800650b960"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Of course! I'd be happy to help you understand more about appendicitis and its treatment options. \n",
            "Common Symptoms of Appendicitis:\n",
            "The common symptoms of appendicitis include:\n",
            "1. Abdominal pain: The most distinctive sign of appendicitis is abdominal pain, which usually starts near the navel and then moves to the lower right side of the abdomen. The pain can be sudden and severe, and may worsen with movement or deep breathing.\n",
            "2. Nausea and vomiting: Patients with appendicitis often experience nausea and vomiting, which can lead to dehydration and electrolyte imbalances.\n",
            "3. Loss of appetite: A person with appendicitis may lose their appetite due to the severe abdominal pain and discomfort.\n",
            "4. Fever: Appendicitis often causes a high fever, which can range from 100°F to 102°F (37.8°C to 39°C).\n",
            "5. Abdominal tenderness: The abdomen is usually tender to the touch in the lower right quadrant, especially around the navel.\n",
            "6. Rigidity and guarding: As the appendix inflames, the muscles in the abdomen may become rigid and guarded, which can make it difficult for a doctor to perform a proper examination.\n",
            "Can Appendicitis be Cured via Medicine?\n",
            "While antibiotics can help manage some of the symptoms associated with appendicitis, such as fever and infection, they cannot cure the underlying condition itself. The only way to treat appendicitis is through surgical removal of the inflamed appendix (appendectomy).\n",
            "Surgical Procedure for Treating Appendicitis:\n",
            "The surgical procedure for treating appendicitis involves removing the inflamed appendix, usually through a laparoscopic or open appendectomy. The choice of surgical approach depends on various factors, including the severity of the appendicitis and the patient's overall health status.\n",
            "Laparoscopic Appendectomy: In this minimally invasive procedure, the surgeon makes several small incisions in the abdomen and inserts a laparoscope (a thin tube with a camera and light) to visualize the appendix. The inflamed appendix is then removed through one of the small incisions.\n",
            "Open Appendectomy: If the appendicitis is severe or there are complications, an open appendectomy may be necessary. In this procedure, a larger incision is made in the abdomen to allow for better visualization and access to the inflamed appendix.\n",
            "In conclusion, while antibiotics can help manage some of the symptoms associated with appendicitis, the only way to cure the condition is through surgical removal of the inflamed appendix. The choice of surgical approach depends on various factors, including the severity of the appendicitis and the patient's overall health status. It's essential to seek medical attention immediately if you suspect that you or someone else may have appendicitis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Comments/Observations on the LLM-Generated Response:Query 2:**\n",
        "\n",
        "- The response provides a clear and structured overview of appendicitis, covering both symptoms and treatment options.\n",
        "- Common symptoms are listed in detail, accurately reflecting clinical presentation.\n",
        "- The explanation distinguishes between symptom management with antibiotics and definitive treatment via surgery, which is medically accurate.\n",
        "- Both laparoscopic and open appendectomy procedures are described, highlighting when each might be used.\n",
        "- The response emphasizes the urgency of seeking medical attention, which is important for patient safety.\n",
        "- Overall, the information is comprehensive, factually correct, and presented in a patient-friendly manner.\n",
        "- The tone is supportive and informative, making the content accessible to non-medical readers."
      ],
      "metadata": {
        "id": "m4iXYgSszu_D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oflaoOGiFjVd"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user's question about treatments and causes of sudden patchy hair loss (localized bald spots)\n",
        "user_prompt = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
        "\n",
        "# Generate a response from the Llama language model using the defined user prompt\n",
        "response = generate_llama_response(user_prompt)\n",
        "\n",
        "# Print the generated response to the console\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fujpQiBUHnb",
        "outputId": "b2c8717f-fdd2-4f9e-bd35-24020eedbb8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sure! I'd be happy to help you with your query. Sudden patchy hair loss, also known as localized bald spots or alopecia areata, can be a distressing condition that affects both men and women. Here are some possible causes and effective treatments for addressing sudden patchy hair loss:\n",
            "Causes of Sudden Patchy Hair Loss:\n",
            "1. Autoimmune Disorders: In this condition, the immune system mistakenly attacks healthy hair follicles, leading to hair loss. Alopecia areata is a common autoimmune disorder that can cause patchy hair loss.\n",
            "2. Genetics: If you have a family history of balding or alopecia areata, you may be more prone to sudden patchy hair loss.\n",
            "3. Hormonal Imbalances: Hormonal fluctuations during pregnancy, menopause, or thyroid disorders can cause sudden patchy hair loss in some individuals.\n",
            "4. Stress and Emotional Distress: Prolonged stress and emotional distress can lead to telogen effluvium, a condition where there is an increase in the number of hair follicles that stop growing and enter the resting phase, leading to patchy hair loss.\n",
            "5. Nutritional Deficiencies: Lack of essential nutrients such as iron, zinc, or biotin can contribute to sudden patchy hair loss.\n",
            "Effective Treatments for Sudden Patchy Hair Loss:\n",
            "1. Medications: Minoxidil (Rogaine) and finasteride (Propecia) are two commonly prescribed medications that can help stimulate hair growth and slow down hair loss. Corticosteroids, immunomodulators, or anthralin may also be used to treat alopecia areata.\n",
            "2. Low-Level Laser Therapy: This non-invasive treatment involves the use of a handheld device that emits low-level laser or light-emitting diodes (LEDs) to stimulate hair growth and improve scalp health.\n",
            "3. Platelet-Rich Plasma (PRP) Therapy: PRP therapy involves injecting platelets rich in growth factors into the affected area, which can help promote hair growth and repair damaged follicles.\n",
            "4. Hair Transplantation: In this surgical procedure, healthy hair follicles are harvested from the back or sides of the head and transplanted to the balding areas.\n",
            "5. Dietary Changes: Making changes to your diet can help address nutritional deficiencies that may be contributing to sudden patchy hair loss. Eating a balanced diet rich in iron, zinc, biotin, and other essential vitamins and minerals can promote healthy hair growth.\n",
            "6. Reducing Stress: Practicing stress-reducing techniques such as meditation or yoga can help manage emotional distress that may be contributing to telogen effluvium.\n",
            "7. Hair Care Routine: Adopting a gentle and nourishing hair care routine, using sulfate-free shampoos, avoiding heat styling tools, and reducing the use of harsh chemical treatments can help promote healthy hair growth and reduce sudden patchy hair loss.\n",
            "In conclusion, sudden patchy hair loss can be caused by a variety of factors, including autoimmune disorders, genetics, hormonal imbalances, stress, nutritional deficiencies, and more. Treatment options range from medications to surgical procedures like hair transplantation or low-level laser therapy. By identifying the underlying cause of sudden patchy hair loss and adopting a comprehensive treatment plan, it is possible to promote healthy hair growth and restore a full and luscious head of hair.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Comments/Observations on the LLM-Generated Response: Query 3**\n",
        "\n",
        "- The response provides a comprehensive overview of both causes and treatments for sudden patchy hair loss.\n",
        "- Causes are clearly categorized, covering autoimmune, genetic, hormonal, stress-related, and nutritional factors.\n",
        "- Treatment options are detailed and include both medical (medications, corticosteroids), procedural (PRP therapy, hair transplantation), and lifestyle interventions (diet, stress reduction, hair care).\n",
        "- The explanation of each treatment is concise and accurate, reflecting current clinical practices.\n",
        "- The response emphasizes the importance of identifying the underlying cause for effective management.\n",
        "- The tone is supportive and informative, making the information accessible to a broad audience.\n",
        "- Overall, the content is well-structured, factually correct, and offers actionable advice for individuals experiencing patchy hair loss."
      ],
      "metadata": {
        "id": "BOBTwP040LI8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUUqY4FbFjVe"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user's question about recommended treatments for brain injuries causing impairment\n",
        "user_prompt = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
        "\n",
        "# Generate a response from the Llama language model using the defined user prompt\n",
        "response = generate_llama_response(user_prompt)\n",
        "\n",
        "# Print the generated response to the console\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-EZV-jyUVgd",
        "outputId": "ca25fb74-1d76-46eb-f3de-f8d9d6905fa6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Depending on the severity and location of the injury, various treatments may be recommended for a person who has sustained a physical injury to brain tissue resulting in temporary or permanent impairment of brain function. These treatments can include:\n",
            "1. Medications: To manage symptoms such as pain, inflammation, and swelling, medications such as analgesics, anti-inflammatory drugs, and corticosteroids may be prescribed.\n",
            "2. Rehabilitation therapy: Physical, occupational, and speech therapy can help restore lost functions and improve cognitive, motor, and communication skills.\n",
            "3. Surgery: In some cases, surgery may be necessary to relieve pressure on the brain or repair damaged blood vessels.\n",
            "4. Cognitive rehabilitation: This type of therapy helps individuals with cognitive impairments resulting from brain injury to improve their memory, attention, and other cognitive functions.\n",
            "5. Behavioral interventions: These may include counseling and psychotherapy to help the individual cope with emotional and behavioral changes resulting from the injury.\n",
            "6. Assistive technology: Devices such as canes, walkers, and communication aids may be recommended to help individuals with mobility or communication difficulties.\n",
            "7. Home modifications: Changes to the home environment, such as installing handrails or non-slip surfaces, may be necessary to ensure safety and independence.\n",
            "8. Support groups: Joining a support group can provide emotional support and connectivity with others who have experienced similar injuries.\n",
            "9. Alternative therapies: Some people may find alternative therapies such as acupuncture or massage helpful in managing their symptoms.\n",
            "It is important to note that the most effective treatment plan will depend on the individual's specific needs and circumstances, and may involve a combination of these options. A healthcare professional can provide guidance on the best course of treatment for each person.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comments/Observations on the LLM-Generated Response:Query 4**\n",
        "\n",
        "- The response provides a thorough overview of treatment options for brain injuries, covering both medical and supportive interventions.\n",
        "- It accurately lists a range of therapies, including medications, rehabilitation, surgery, cognitive and behavioral interventions, and assistive technologies.\n",
        "- The inclusion of home modifications and support groups demonstrates a holistic approach to patient care.\n",
        "- Alternative therapies are mentioned, reflecting awareness of complementary treatment options.\n",
        "- The response emphasizes individualized care and the importance of professional guidance, which aligns with best clinical practices.\n",
        "- Overall, the information is comprehensive, well-structured, and accessible to a broad audience."
      ],
      "metadata": {
        "id": "v1CjsGhH1IQj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5laPFTHrFjVf"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user's question about precautions and treatment for a leg fracture sustained during hiking\n",
        "user_prompt = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
        "\n",
        "# Generate a response from the Llama language model using the provided user prompt\n",
        "response = generate_llama_response(user_prompt)\n",
        "\n",
        "# Print the model's generated response to the console\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkHeK-UYUh3y",
        "outputId": "febb84ec-888f-45c6-cb1d-09ef238875bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " If you have fractured your leg while hiking, it is essential to seek medical attention as soon as possible. Here are some necessary precautions and treatment steps:\n",
            "Precautions:\n",
            "1. Immobilize the injured limb: Use a splint or bandage to immobilize the affected leg to prevent further injury or movement. This will help reduce pain and promote healing.\n",
            "2. Apply ice packs: Ice can be applied to the affected area to reduce swelling and relieve pain. Wrap an ice pack in a cloth to avoid direct contact with the skin.\n",
            "3. Elevate the injured limb: Elevating the leg above heart level can help reduce swelling and promote blood flow.\n",
            "4. Monitor for signs of complications: Keep an eye out for signs of infection, such as redness, swelling, or increased pain. If you notice any of these symptoms, seek medical attention immediately.\n",
            "Treatment Steps:\n",
            "1. X-rays and imaging tests: A healthcare professional will take x-rays to determine the severity of the fracture and create a treatment plan. Depending on the type and location of the fracture, you may need surgery or other treatments such as casts, braces, or physical therapy.\n",
            "2. Medication: Your healthcare provider will prescribe pain medications to manage discomfort during the healing process. They may also recommend anti-inflammatory drugs to reduce swelling and promote healing.\n",
            "3. Casting or bracing: Depending on the severity of the fracture, you may need a cast or brace to immobilize the affected limb while it heals. This will help prevent further injury or movement during the recovery process.\n",
            "4. Physical therapy: After the initial healing phase, physical therapy can be helpful in restoring strength and range of motion in your leg. A healthcare professional will work with you to create a customized exercise program that promotes healing while minimizing discomfort or pain.\n",
            "Care and Recovery Considerations:\n",
            "1. Follow-up appointments: It is essential to follow up with your healthcare provider regularly during the recovery process to monitor progress, address any concerns, and make adjustments to your treatment plan as needed.\n",
            "2. Rest and relaxation: Allow yourself time to rest and recover after the injury. Avoid putting too much strain on the affected limb or engaging in strenuous activities until it has fully healed.\n",
            "3. Compression garments: Wearing compression stockings or sleeves can help reduce swelling during the recovery process, especially if you have a leg fracture that is high up (such as ankle or knee).\n",
            "4. Proper nutrition and hydration: Eating a balanced diet rich in calcium and vitamin D will promote bone healing. Staying well-hydrated can also help with the recovery process by flushing out toxins from your body more efficiently.\n",
            "In conclusion, if you have fractured your leg while hiking, it is crucial to seek medical attention promptly and follow proper precautions and treatment steps for a successful recovery. Remember to prioritize rest and relaxation during the healing process and make adjustments as needed based on how your body responds to different treatments.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comments/Observations on the LLM-Generated Response:Query 5**\n",
        "\n",
        "- The response provides a clear, step-by-step guide for immediate precautions and treatment following a leg fracture.\n",
        "- It emphasizes the importance of immobilization, ice application, elevation, and monitoring for complications, which are standard first-aid measures.\n",
        "- The treatment section accurately covers diagnostic imaging, medication, immobilization, and the role of physical therapy in recovery.\n",
        "- Care and recovery considerations such as follow-up, rest, compression garments, and nutrition are included, reflecting a holistic approach.\n",
        "- The advice to seek prompt medical attention and avoid self-treatment is appropriate and prioritizes patient safety.\n",
        "- The information is well-structured, comprehensive, and accessible to non-medical readers.\n",
        "- Overall, the response aligns with best practices for fracture management and provides actionable, practical guidance.\n",
        "```"
      ],
      "metadata": {
        "id": "UspTPcJP1qKL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5myZ5dOOefc"
      },
      "source": [
        "# Question Answering using LLM with Prompt Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### As per the rubrics, LLM parameter tuning (at least 5 combinations)"
      ],
      "metadata": {
        "id": "rlJLLUY91urU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination - 1 :  Low randomness for more deterministic, factual output"
      ],
      "metadata": {
        "id": "jFkfXLFX07rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using a specific combination of parameters for sepsis management queries\n",
        "def generate_llama_response_combo1(user_prompt):\n",
        "    # Define a system message providing context and specific instruction for summarizing clinical guidelines\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Summarize the most up-to-date clinical guidelines for sepsis management in the ICU, with a focus on evidence-based practices.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user prompt and the system message to form the full prompt sent to the language model\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model (llm) with the combined prompt and specified parameter values for generation\n",
        "    response = llm(\n",
        "        prompt=prompt,            # The full prompt including user input and instructions\n",
        "        max_tokens=600,           # Maximum number of tokens to generate in the response\n",
        "        temperature=0.2,          # Low randomness for more deterministic, factual output\n",
        "        top_p=0.9,                # Nucleus sampling parameter to limit diversity of output\n",
        "        repeat_penalty=1.1,       # Slight penalty to discourage repeated phrases\n",
        "        top_k=40,                 # Only consider the top 40 tokens at each step for next token prediction\n",
        "        stop=[\"INST\"],            # Stop generating output if the string \"INST\" is encountered\n",
        "        echo=False                # Do not include the prompt in the response output\n",
        "    )\n",
        "    # Return the text of the generated response from the model's output\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "c-OXaea40_Ie"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination - 2 : Controls randomness/creativity of the output,  No additional penalty for repeating phrases"
      ],
      "metadata": {
        "id": "gALIbnu51FAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using a second set of parameters for sepsis management queries\n",
        "def generate_llama_response_combo2(user_prompt):\n",
        "    # Define a system message to instruct the LLM to provide a detailed, step-by-step treatment protocol\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Provide a detailed step-by-step treatment protocol for managing sepsis in an ICU.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user prompt and system message into a single prompt for the LLM\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the LLM with the prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt including user input and instructions\n",
        "        max_tokens=768,         # Sets the maximum length for the generated response (in tokens)\n",
        "        temperature=0.4,        # Controls randomness/creativity of the output (moderate value)\n",
        "        top_p=0.85,             # Nucleus sampling: considers tokens with cumulative probability up to 0.85\n",
        "        repeat_penalty=1.0,     # No additional penalty for repeating phrases\n",
        "        top_k=60,               # Considers only the top 60 most likely tokens at each step\n",
        "        stop=[\"INST\"],          # Halts output generation if the string \"INST\" is encountered\n",
        "        echo=False              # Does not include the prompt itself in the output\n",
        "    )\n",
        "    # Extract and return the generated text response from the LLM output\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "Bt1Non-d1JqH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination - 3 : Controls the randomness/creativity of the output (higher value allows more variety), Slight penalty to discourage repeated phrases in the output"
      ],
      "metadata": {
        "id": "Bmb1J2JI1Oe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using a third combination of parameters for sepsis management queries\n",
        "def generate_llama_response_combo3(user_prompt):\n",
        "    # Define a system message to instruct the LLM to compare current and older ICU sepsis protocols, focusing on improvements and rationale\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Explain how current ICU sepsis protocols differ from older practices, emphasizing the improvements and rationale behind them.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user prompt and system message into a single prompt for the LLM\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the LLM with the prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt including user input and instructions\n",
        "        max_tokens=700,         # Set the maximum length for the generated response (in tokens)\n",
        "        temperature=0.6,        # Controls the randomness/creativity of the output (higher value allows more variety)\n",
        "        top_p=0.95,             # Nucleus sampling: considers tokens with cumulative probability up to 0.95\n",
        "        repeat_penalty=1.1,     # Slight penalty to discourage repeated phrases in the output\n",
        "        top_k=50,               # Considers only the top 50 most likely tokens at each step\n",
        "        stop=[\"INST\"],          # Halts output generation if the string \"INST\" is encountered\n",
        "        echo=False              # Does not include the prompt itself in the output\n",
        "    )\n",
        "    # Extract and return the generated text response from the LLM output\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "axbHWIET1SJO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination - 4 : Very low randomness for highly focused and factual output,  Strong penalty to discourage repeated phrases or words in the output"
      ],
      "metadata": {
        "id": "ouhxuiSi1VI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using a fourth combination of parameters for sepsis management queries\n",
        "def generate_llama_response_combo4(user_prompt):\n",
        "    # Define a system message instructing the LLM to format its response as a checklist summarizing key ICU interventions for sepsis management\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Format your response as a checklist summarizing ICU interventions for managing sepsis, from diagnosis to stabilization.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user prompt and system message into a single prompt for the LLM\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the LLM with the prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt, including user input and checklist formatting instruction\n",
        "        max_tokens=400,         # Sets the maximum length for the generated response (in tokens)\n",
        "        temperature=0.1,        # Very low randomness for highly focused and factual output\n",
        "        top_p=0.7,              # Nucleus sampling: considers tokens with cumulative probability up to 0.7 (less diversity)\n",
        "        repeat_penalty=1.3,     # Strong penalty to discourage repeated phrases or words in the output\n",
        "        top_k=30,               # Considers only the top 30 most likely tokens at each step\n",
        "        stop=[\"INST\"],          # Halts output generation if the string \"INST\" is encountered\n",
        "        echo=False              # Does not include the prompt itself in the output\n",
        "    )\n",
        "    # Extract and return the generated text response from the LLM output\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "_HFQd19_1X5-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination - 5:  Nucleus sampling: considers tokens with cumulative probability up to 1.0 (maximum diversity)"
      ],
      "metadata": {
        "id": "QgD86z8G1aKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using a fifth combination of parameters for sepsis management queries\n",
        "def generate_llama_response_combo5(user_prompt):\n",
        "    # Define a system message instructing the LLM to explain ICU sepsis management as if teaching a junior medical resident, using clear and conversational language\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Imagine you're explaining ICU sepsis management to a junior medical resident. Use clear, educational, and conversational language.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user prompt and system message into a single prompt for the LLM\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the LLM function with the prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The complete prompt, including user input and instructional context\n",
        "        max_tokens=650,         # Set the maximum length for the generated response (in tokens)\n",
        "        temperature=0.8,        # Higher randomness for a more conversational and educational tone\n",
        "        top_p=1.0,              # Nucleus sampling: considers tokens with cumulative probability up to 1.0 (maximum diversity)\n",
        "        repeat_penalty=1.0,     # No additional penalty for repeated phrases\n",
        "        top_k=80,               # Considers the top 80 most likely tokens at each step\n",
        "        stop=[\"INST\"],          # Stops generation if the string \"INST\" is encountered\n",
        "        echo=False              # Does not include the prompt itself in the generated output\n",
        "    )\n",
        "    # Extract and return the generated text response from the LLM output\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "-QabJPZM1cqZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapper function to run all the combinations"
      ],
      "metadata": {
        "id": "lwARDfAg1i1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all_llama_response_combos(user_prompt):\n",
        "    results = {\n",
        "        \"Combo 1 – Clinical Guideline Summary\": generate_llama_response_combo1(user_prompt),\n",
        "        \"Combo 2 – Step-by-Step Protocol\": generate_llama_response_combo2(user_prompt),\n",
        "        \"Combo 3 – Modern vs. Traditional\": generate_llama_response_combo3(user_prompt),\n",
        "        \"Combo 4 – Protocol Checklist\": generate_llama_response_combo4(user_prompt),\n",
        "        \"Combo 5 – Teaching Style Explanation\": generate_llama_response_combo5(user_prompt),\n",
        "    }\n",
        "\n",
        "    for title, response in results.items():\n",
        "        print(f\"\\n=== {title} ===\\n{response}\\n{'=' * 60}\")"
      ],
      "metadata": {
        "id": "OmCdFN1H1npQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jg3r_LWOeff"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the question about sepsis management protocols in a critical care unit\n",
        "question = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "\n",
        "# Call the function to run all predefined Llama model response parameter combinations with the given question\n",
        "run_all_llama_response_combos(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKRUvuWt3JTL",
        "outputId": "9b73f038-423e-47db-ea9e-dc94f4edb186"
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Combo 1 – Clinical Guideline Summary ===\n",
            " Managing sepsis in a critical care unit requires prompt and effective interventions to address the complex physiological derangements that occur in this life-threatening condition. The Surviving Sepsis Campaign (SSC) and the Society of Critical Care Medicine (SCCM) have developed evidence-based guidelines for sepsis management in the intensive care unit (ICU). Here are some key updates from the most recent clinical guidelines:\n",
            "1. Early recognition and activation of sepsis protocols: The SSC/SCCM guidelines emphasize the importance of early recognition and activation of sepsis protocols, including prompt administration of antibiotics and fluid resuscitation.\n",
            "2. Vasopressor therapy: The guidelines recommend using vasopressors to maintain mean arterial pressure (MAP) ≥65 mmHg in septic patients with hypotension (defined as MAP <65 mmHg). However, the choice of vasopressor should be based on the patient's hemodynamic status and other factors.\n",
            "3. Goal-directed therapy: The guidelines recommend using goal-directed therapy to manage septic shock, which involves targeting a MAP of ≥65 mmHg and a central venous pressure (CVP) of ≤8 mmHg.\n",
            "4. Hemodynamic support: The guidelines recommend using hemodynamic support strategies, such as vasopressors and inotropes, to manage septic shock. However, the choice of therapy should be based on the patient's response to treatment and other factors.\n",
            "5. Steroid use: The guidelines advise against the routine use of corticosteroids in sepsis, as there is no evidence to support their benefit in this condition.\n",
            "6. Antibiotic selection: The guidelines recommend using broad-spectrum antibiotics effective against common causes of sepsis, such as Gram-positive and Gram-negative bacteria. However, the choice of antibiotic should be based on the patient's suspected infection and other factors.\n",
            "7. Renal replacement therapy: The guidelines recommend using renal replacement therapy (RRT) in septic patients with acute kidney injury (AKI), as it can improve survival and reduce the risk of organ failure.\n",
            "8. Cardiac support: The guidelines recommend using cardiac support strategies, such as mechanical ventilation and cardiopulmonary resuscitation, to manage cardiovascular dysfunction in septic patients.\n",
            "9. Neurological support: The guidelines recommend using neurological support strategies, such as sedation\n",
            "============================================================\n",
            "\n",
            "=== Combo 2 – Step-by-Step Protocol ===\n",
            "1. Assessment and Identification:\n",
            "a. Rapidly assess the patient's vital signs, particularly temperature, tachycardia, tachypnea, and blood pressure.\n",
            "b. Identify the source of infection (e.g., urinary tract, respiratory, or surgical site) and the severity of sepsis (e.g., severe sepsis or septic shock).\n",
            "c. Document the patient's vital signs and infection source in the medical record.\n",
            "2. Fluid Resuscitation:\n",
            "a. Administer 30-50 mL/kg of crystalloid fluid (e.g., normal saline or lactated Ringer's solution) for hypotension (defined as a mean arterial pressure [MAP] ≤65 mmHg) or tachycardia (heart rate ≥90 beats per minute).\n",
            "b. Monitor the patient's fluid balance and adjust fluid resuscitation as needed.\n",
            "c. Consider the use of vasopressors (e.g., norepinephrine or epinephrine) if MAP remains <65 mmHg despite fluid resuscitation.\n",
            "3. Antibiotics:\n",
            "a. Administer broad-spectrum antibiotics effective against common sepsis pathogens (e.g., Gram-positive and Gram-negative bacteria, Candida, and Aspergillus).\n",
            "b. Choose antibiotics based on the suspected source of infection and the patient's medical history.\n",
            "c. Monitor the patient's response to antibiotics and adjust the antibiotic regimen as needed.\n",
            "4. Vasopressor Therapy:\n",
            "a. Consider the use of vasopressors (e.g., norepinephrine or epinephrine) if the patient is in septic shock (defined as MAP <65 mmHg despite fluid resuscitation) or if the patient's MAP is <70 mmHg despite fluid resuscitation and antibiotics.\n",
            "b. Titrate the vasopressor dose to maintain an MAP ≥65 mmHg.\n",
            "5. Oxygen Therapy:\n",
            "a. Provide oxygen therapy (e.g., nasal cannula or non-rebreather mask) if the patient's arterial oxygen tension (PaO2) is <60 mmHg.\n",
            "b. Monitor the patient's oxygen saturation and adjust the oxygen therapy as needed.\n",
            "6. Infection Surveillance and Control:\n",
            "a. Implement infection surveillance and control measures (e.g., isolation precautions, hand hygiene, environmental cleaning) to reduce the risk of nosocomial infection.\n",
            "b. Monitor the patient's temperature and vital signs regularly to detect signs of infection early.\n",
            "7. Monitoring and Adjusting Therapy:\n",
            "a. Continuously monitor the patient's vital signs, fluid balance, and response to therapy.\n",
            "b. Adjust therapy as needed based on the patient's clinical status and laboratory values.\n",
            "8. Escalation of Care:\n",
            "a. If the patient's condition worsens or does not improve despite initial therapy, consider escalating care to a higher level of care (e.g., emergency department, operating room, or intensive care unit).\n",
            "\n",
            "============================================================\n",
            "\n",
            "=== Combo 3 – Modern vs. Traditional ===\n",
            " Sepsis is a life-threatening condition that arises from an immune response to infection, which can lead to organ failure and death. Critical care units (ICUs) play a crucial role in managing sepsis, where early recognition and prompt treatment are essential for improving outcomes. The protocols for managing sepsis in ICUs have evolved significantly over the years, with a focus on evidence-based practices that prioritize early intervention and individualized care. Here are some key differences between current ICU sepsis protocols and older practices:\n",
            "1. Early recognition and activation of sepsis team: Current protocols emphasize the importance of early recognition of sepsis, often using clinical prediction rules or scorecards to identify patients at risk of developing sepsis. This allows for prompt activation of the sepsis team, which can include intensivists, infectious disease specialists, and other healthcare professionals. In contrast, older practices may have relied on manual surveillance and clinical judgment alone, leading to delays in recognition and treatment.\n",
            "2. Aggressive fluid resuscitation: Fluid management is critical in sepsis, with current protocols advocating for early administration of vasopressors and large volumes of crystalloid fluids. This approach is based on evidence showing that early fluid resuscitation can improve organ perfusion and reduce the risk of organ failure. In contrast, older practices may have delayed fluid resuscitation, which could lead to hypotension and worsening organ function.\n",
            "3. Early administration of antibiotics: Current protocols emphasize the importance of early administration of broad-spectrum antibiotics effective against common sepsis pathogens. This approach is based on evidence showing that timely administration of antibiotics can improve survival and reduce the risk of complications. In contrast, older practices may have delayed antibiotic administration, which could lead to prolonged bacteremia and increased risk of organ failure.\n",
            "4. Renal replacement therapy: Current protocols recommend early initiation of renal replacement therapy (RRT) in patients with acute kidney injury (AKI), particularly those with sepsis-induced AKI. This approach is based on evidence showing that early RRT can improve survival and reduce the risk of complications. In contrast, older practices may have delayed initiation of RRT, which could lead to worsening renal function and increased risk of morbidity.\n",
            "5. Use of vasopressors: Current protocols recommend the use of vasopressors in sepsis patients with hypotension, particularly those with septic shock. This approach is based on evidence showing that vasopressors can improve organ perfusion and reduce the risk of organ failure. In contrast, older practices may have used vasopressors less frequently or with less intensity, which could lead to inadequate perfusion and worsening outcomes.\n",
            "6. Use of sedation and analgesia: Current protocols emphasize the importance of adequate sedation and analgesia in sepsis patients, particularly those with septic shock. This approach is based on evidence showing that appropriate sedation can improve patient comfort and reduce the risk of del\n",
            "============================================================\n",
            "\n",
            "=== Combo 4 – Protocol Checklist ===\n",
            " Sure! Here is a comprehensive checklist outlining the protocols and interventions for managing sepsis in a critical care unit (ICU):\n",
            "Diagnosis:\n",
            "1. Confirm the presence of sepsis through laboratory tests, including complete blood count (CBC), electrolyte levels, lactate level, and urinalysis.\n",
            "2. Identify potential sources of infection based on patient history, physical examination findings, and laboratory results.\n",
            "3. Initiate broad-spectrum antibiotics effective against likely pathogens within 1 hour of sepsis diagnosis.\n",
            "Stabilization:\n",
            "4. Monitor vital signs every 2 hours or as clinically indicated to identify changes in cardiovascular function, respiratory status, and temperature regulation.\n",
            "5. Provide oxygen therapy according to arterial blood gas (ABG) analysis results.\n",
            "6. Administer vasopressors if hypotension persists despite fluid resuscitation or if mean arterial pressure (MAP) is < 70 mmHg.\n",
            "7. Manage fever aggressively with medication and/or cooling measures as needed to maintain body temperature within a normal range.\n",
            "8. Provide early recognition of organ dysfunction, including cardiovascular collapse, respiratory failure, hepatic encephalopathy, acute kidney injury (AKI), or coagulopathies.\n",
            "9. Implement appropriate fluid management strategies to maintain adequate circulating blood volume and organ perfusion while avoiding overload-related complications such as pulmonary edema or cardiac failure.\n",
            "10. Monitor for signs of sepsis progression, including systemic inflammatory response syndrome (SIRS) criteria fulfillment,\n",
            "============================================================\n",
            "\n",
            "=== Combo 5 – Teaching Style Explanation ===\n",
            " Sure, I'd be happy to help explain ICU sepsis management to a junior medical resident! Sepsis is a serious and sometimes life-threatening condition that occurs when the body's response to an infection becomes uncontrolled and causes widespread inflammation. In the intensive care unit (ICU), managing sepsis requires a coordinated and multi-disciplinary approach involving the entire healthcare team.\n",
            "First and foremost, it's important to quickly identify and diagnose sepsis in the ICU patient. This involves a thorough assessment of the patient's vital signs, laboratory values, and clinical presentation. The Sepsis-3 definition and scoring system can be used to help guide this evaluation.\n",
            "Once sepsis is confirmed, the next step is to stabilize the patient's vital functions and prevent further organ damage. This may involve providing oxygen therapy, fluids, and medications to maintain blood pressure and blood flow to vital organs. In some cases, vasopressors may be used to support blood pressure and cardiac function.\n",
            "In addition to these supportive measures, antibiotics are essential in managing sepsis. The choice of antibiotic will depend on the suspected source of infection and the patient's medical history. It's important to initiate antibiotics promptly and adjust the dosage and duration of therapy based on the patient's clinical response.\n",
            "Beyond these interventions, there are several advanced therapies that may be employed to treat sepsis in the ICU. These include:\n",
            "1. Early Goal-Directed Therapy (EGDT): This is a bundle of interventions that focuses on promptly addressing the patient's cardiovascular dysfunction and organ dysfunction. EGDT includes measures to elevate blood pressure, improve cardiac function, and address metabolic derangements.\n",
            "2. Cardiac echo and cardiac catheterization: In some cases, these tests may be necessary to evaluate the patient's cardiac function and identify any potential sources of cardiac dysfunction.\n",
            "3. Renal replacement therapy: This may be necessary if the patient's kidneys are unable to adequately filter waste products from the blood.\n",
            "4. ECMO and VA-ECMO: These are advanced life support measures that may be employed in severe cases of sepsis where other therapies have failed.\n",
            "5. Artificial ventilation and extracorporeal membrane oxygenation (ECMO): These measures may be necessary if the patient's respiratory and cardiac functions are severely compromised.\n",
            "6. Infectious disease consultation: Given the complex nature of sepsis, it's important to consult with an infectious disease specialist to help guide the management of the infection.\n",
            "7. Nutritional support: Providing adequate nutrition is critical in the\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYpyw4HjOeff"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 1 – Clinical Guideline Summary (Deterministic)"
      ],
      "metadata": {
        "id": "Gl9PVyH-9JAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using the first combination of parameters for sepsis management queries\n",
        "def generate_llama_response_combo1(user_prompt):\n",
        "    # Create a system message instructing the LLM to summarize current clinical guidelines for ICU sepsis management, focusing on evidence-based practices\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Summarize the most up-to-date clinical guidelines for sepsis management in the ICU, with a focus on evidence-based practices.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the LLM (language model) with the combined prompt and a specific set of parameters for text generation\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt to be sent to the language model\n",
        "        max_tokens=600,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.2,        # Low temperature for a more deterministic, less random response\n",
        "        top_p=0.9,              # Nucleus sampling parameter: considers tokens with cumulative probability up to 0.9\n",
        "        repeat_penalty=1.1,     # Slight penalty to discourage repeated text in the output\n",
        "        top_k=40,               # Considers only the top 40 most likely tokens for each step\n",
        "        stop=[\"INST\"],          # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False              # Exclude the input prompt from the response output\n",
        "    )\n",
        "    # Return the generated text from the response dictionary\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "J5QR6Far9TZ1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 2 – Step-by-Step Protocol (Process-Oriented)"
      ],
      "metadata": {
        "id": "TGuNH1Zg9dHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate a response from the LLM using the second parameter combination for sepsis management queries\n",
        "def generate_llama_response_combo2(user_prompt):\n",
        "    # Create a system message instructing the LLM to provide a detailed, step-by-step treatment protocol for sepsis in an ICU\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Provide a detailed step-by-step treatment protocol for managing sepsis in an ICU.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user prompt and the system message into a single prompt string for the LLM\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the LLM with the constructed prompt and specific generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The complete prompt to be sent to the language model\n",
        "        max_tokens=768,         # Set the maximum number of tokens to generate in the response\n",
        "        temperature=0.4,        # Set the randomness/creativity of the output (moderate value)\n",
        "        top_p=0.85,             # Nucleus sampling: consider tokens with cumulative probability up to 0.85\n",
        "        repeat_penalty=1.0,     # No additional penalty for repeated phrases (default value)\n",
        "        top_k=60,               # Consider the top 60 most likely tokens at each generation step\n",
        "        stop=[\"INST\"],          # Stop generating output if the string \"INST\" is encountered\n",
        "        echo=False              # Do not include the input prompt in the output\n",
        "    )\n",
        "    # Return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "VuliWM_q9ruC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 3 – Modern vs. Traditional (Comparative, Narrative)"
      ],
      "metadata": {
        "id": "oZKD-CMb90U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate a response from the LLM using the third set of parameters for sepsis management queries\n",
        "def generate_llama_response_combo3(user_prompt):\n",
        "    # Create a system message instructing the LLM to explain differences between current and older ICU sepsis protocols,\n",
        "    # with an emphasis on improvements and the rationale behind changes\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Explain how current ICU sepsis protocols differ from older practices, emphasizing the improvements and rationale behind them.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model (llm) with the combined prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt containing user input and system instruction\n",
        "        max_tokens=700,         # Maximum number of tokens to generate in the response\n",
        "        temperature=0.6,        # Controls randomness/creativity of the output (moderate value for balanced results)\n",
        "        top_p=0.95,             # Nucleus sampling: considers tokens with cumulative probability up to 0.95 (more diversity)\n",
        "        repeat_penalty=1.1,     # Slight penalty to discourage repeated phrases in the output\n",
        "        top_k=50,               # Considers only the top 50 most likely tokens for each step\n",
        "        stop=[\"INST\"],          # Stops generation if the string \"INST\" appears in the output\n",
        "        echo=False              # Excludes the prompt itself from the output\n",
        "    )\n",
        "    # Return the generated text from the response dictionary\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "44USzcL6-IcO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 4 – Protocol Checklist (Concise & Actionable)"
      ],
      "metadata": {
        "id": "_WVhIpop-XGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate a response from the LLM using the fourth set of parameters for sepsis management queries\n",
        "def generate_llama_response_combo4(user_prompt):\n",
        "    # Create a system message instructing the LLM to format its response as a checklist summarizing ICU interventions for sepsis, from diagnosis to stabilization\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Format your response as a checklist summarizing ICU interventions for managing sepsis, from diagnosis to stabilization.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the LLM with the constructed prompt and specific generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The complete prompt to be sent to the language model\n",
        "        max_tokens=400,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.1,        # Very low temperature for a highly focused and factual output\n",
        "        top_p=0.7,              # Nucleus sampling: consider tokens with cumulative probability up to 0.7 (less diversity)\n",
        "        repeat_penalty=1.3,     # Strong penalty to discourage repeated phrases or words in the output\n",
        "        top_k=30,               # Consider only the top 30 most likely tokens at each generation step\n",
        "        stop=[\"INST\"],          # Stop generating output if the string \"INST\" is encountered\n",
        "        echo=False              # Do not include the input prompt in the output\n",
        "    )\n",
        "    # Return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "PN6wGGK6-lre"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 5 – Teaching Style (Conversational & Educational)"
      ],
      "metadata": {
        "id": "2LKYMJ8X-tsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate a response from the LLM using the fifth set of parameters for sepsis management queries\n",
        "def generate_llama_response_combo5(user_prompt):\n",
        "    # Create a system message instructing the LLM to explain ICU sepsis management as if teaching a junior medical resident, using clear and conversational language\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Imagine you're explaining ICU sepsis management to a junior medical resident. Use clear, educational, and conversational language.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the LLM with the constructed prompt and specific generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The complete prompt to be sent to the language model\n",
        "        max_tokens=650,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.8,        # Higher temperature for more creativity and conversational style\n",
        "        top_p=1.0,              # Nucleus sampling: considers tokens with cumulative probability up to 1.0 (maximum diversity)\n",
        "        repeat_penalty=1.0,     # No penalty for repeated phrases (default value)\n",
        "        top_k=80,               # Consider the top 80 most likely tokens at each generation step\n",
        "        stop=[\"INST\"],          # Stop generating output if the string \"INST\" is encountered\n",
        "        echo=False              # Do not include the input prompt in the output\n",
        "    )\n",
        "    # Return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "TrA5PAU9_Kbs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapper function to run all the combinations"
      ],
      "metadata": {
        "id": "KV2EcxLK_O7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to run all Llama response combinations and print their outputs\n",
        "def run_all_llama_response_combos(user_prompt):\n",
        "    # Call each of the predefined response combo functions with the user prompt,\n",
        "    # and store their outputs in a dictionary with descriptive titles as keys\n",
        "    results = {\n",
        "        \"Combo 1 – Clinical Guideline Summary\": generate_llama_response_combo1(user_prompt),\n",
        "        \"Combo 2 – Step-by-Step Protocol\": generate_llama_response_combo2(user_prompt),\n",
        "        \"Combo 3 – Modern vs. Traditional\": generate_llama_response_combo3(user_prompt),\n",
        "        \"Combo 4 – Protocol Checklist\": generate_llama_response_combo4(user_prompt),\n",
        "        \"Combo 5 – Teaching Style Explanation\": generate_llama_response_combo5(user_prompt),\n",
        "    }\n",
        "\n",
        "    # Iterate over each key-value pair in the results dictionary\n",
        "    for title, response in results.items():\n",
        "        # Print the section header, the response, and a separator line for readability\n",
        "        print(f\"\\n=== {title} ===\\n{response}\\n{'=' * 60}\")"
      ],
      "metadata": {
        "id": "U4x-yT-z_Usw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the query"
      ],
      "metadata": {
        "id": "Ubc8_nHf_0Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the sepsis management question to a variable\n",
        "question = \"What is the protocol for managing sepsis in a critical care unit?\"\n",
        "\n",
        "# Call the function to run all Llama response combinations using the question as input\n",
        "run_all_llama_response_combos(question)"
      ],
      "metadata": {
        "id": "aErZuxoW_4On",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265c033b-23df-4eff-ecb4-58dbad03e1be"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Combo 1 – Clinical Guideline Summary ===\n",
            " Managing sepsis in a critical care unit requires prompt and effective interventions to address the complex needs of these patients. The Surviving Sepsis Campaign (SSC) and the Society of Critical Care Medicine (SCCM) have developed evidence-based guidelines for sepsis management in the ICU, which are regularly updated to reflect new research findings. Here is a summary of the most recent clinical guidelines for managing sepsis in the ICU:\n",
            "1. Early recognition and activation of sepsis protocols: Rapid identification and activation of sepsis protocols are critical to ensure timely interventions and improve outcomes. The SSC recommends using a validated screening tool, such as the Quick Sequential Organ Failure Assessment (qSOFA), to identify patients at risk of developing sepsis.\n",
            "2. Resuscitation: Early recognition of hypoperfusion and shock requires prompt resuscitation with vasopressors, fluids, and oxygen. The SCCM recommends a goal-directed approach to fluid management, using central lines for large-volume resuscitation and monitoring central venous pressure (CVP) to guide therapy.\n",
            "3. Source control: Rapid identification and management of the source of infection are essential to prevent further progression of sepsis. The SSC recommends that all patients with suspected infections undergo prompt imaging studies, such as chest X-rays or CT scans, to identify the site of infection.\n",
            "4. Antibiotics: Early administration of broad-spectrum antibiotics is critical to reduce bacterial load and prevent progression of sepsis. The SSC recommends using a β-lactam antibiotic with or without an aminoglycoside, based on the severity of sepsis and the suspected pathogen.\n",
            "5. vasopressor therapy: Early administration of vasopressors is recommended to maintain mean arterial pressure (MAP) ≥65 mmHg in patients with septic shock. The SCCM recommends using a goal-directed approach to vasopressor therapy, based on the patient's MAP and cardiac output.\n",
            "6. Sedation: Proper sedation is essential to manage agitation and prevent injury to the patient. The SSC recommends using a sedation protocol that includes a stepwise approach to sedation, based on the level of consciousness and the presence of delirium.\n",
            "7. Renal support: Early recognition of acute kidney injury (AKI) and prompt management are critical to prevent progression to chronic kidney disease. The SSC recommends using a validated AKI staging system, such as\n",
            "============================================================\n",
            "\n",
            "=== Combo 2 – Step-by-Step Protocol ===\n",
            "1. Assessment and Identification:\n",
            "a. Immediately recognize the signs of sepsis and initiate resuscitation efforts if necessary.\n",
            "b. Obtain a complete medical history, including any recent infections, surgical procedures, or exposure to toxins.\n",
            "c. Perform a thorough physical examination, paying particular attention to vital signs, respiratory status, and cardiac function.\n",
            "d. Order blood cultures and other appropriate diagnostic tests to confirm the presence of infection and identify the causative organism.\n",
            "e. Use the Sepsis-3 definition and the Quick Sequential Organ Failure Assessment (qSOFA) score to assess the severity of sepsis.\n",
            "2. Resuscitation and Supportive Care:\n",
            "a. Provide oxygen therapy as needed to maintain arterial oxygen saturation (SaO2) ≥ 90%.\n",
            "b. Administer vasopressors to maintain mean arterial pressure (MAP) ≥ 65 mmHg.\n",
            "c. Initiate fluid resuscitation with crystalloids or colloids, targeting a fluid balance of 200-300 mL/hour.\n",
            "d. Monitor fluid balance and adjust fluid resuscitation as needed.\n",
            "e. Provide vasopressor therapy and inotropes as needed to maintain MAP ≥ 65 mmHg.\n",
            "f. Manage hypotension and hypovolemia with blood transfusions and fluid resuscitation.\n",
            "3. Antibiotics and Anti-infective Therapy:\n",
            "a. Administer broad-spectrum antibiotics effective against common sepsis pathogens, such as Gram-positive and Gram-negative bacteria, and anaerobes.\n",
            "b. Use a combination of intravenous and inhaled antibiotics, as appropriate.\n",
            "c. Monitor for signs of antibiotic resistance and adjust therapy as needed.\n",
            "d. Provide appropriate antifungal therapy for patients with fungal infections.\n",
            "4. Cardiovascular Support:\n",
            "a. Monitor cardiac function and provide inotropes or vasopressors as needed to maintain MAP ≥ 65 mmHg.\n",
            "b. Manage cardiac dysfunction with medications such as digoxin, lidocaine, or amiodarone.\n",
            "c. Provide mechanical support with devices such as intra-aortic balloon pumps or ventricular assist devices.\n",
            "5. Respiratory Support:\n",
            "a. Monitor respiratory function and provide oxygen therapy as needed.\n",
            "b. Provide mechanical ventilation with a tidal volume of 6-8 mL/kg and a plateau pressure ≤ 30 cmH2O.\n",
            "c. Use non-invasive ventilation (NIV) or invasive ventilation (IV) as needed.\n",
            "6. Neurological Support:\n",
            "a. Monitor neurological function and provide sedation as needed to maintain a level of consciousness.\n",
            "b. Manage seizures with medications such as benzodiazepines or phenytoin.\n",
            "c. Provide neuromuscular blockade with drugs such as sugammadex or rocuronium.\n",
            "7. Renal Support:\n",
            "a. Monitor renal function and provide fluid management as needed to maintain a urine output of 0.5\n",
            "============================================================\n",
            "\n",
            "=== Combo 3 – Modern vs. Traditional ===\n",
            " Sepsis is a life-threatening systemic inflammatory response to an infection, which can lead to organ dysfunction and death. Critical care units (ICUs) play a crucial role in managing sepsis through early recognition, prompt treatment, and close monitoring. The protocols for managing sepsis in ICUs have evolved significantly over the years, with a shift towards more evidence-based practices that prioritize early recognition and aggressive therapy. Here are some key differences between current ICU sepsis protocols and older practices:\n",
            "1. Early recognition and activation of sepsis protocols: Older protocols relied on clinical judgment to identify sepsis, leading to delays in diagnosis and treatment. Current protocols use standardized scoring systems like the Quick Sequential Organ Failure Assessment (qSOFA) or the Systemic Inflammatory Response Syndrome (SIRS) criteria to quickly identify patients at risk of developing sepsis. This enables early activation of sepsis protocols and timely interventions.\n",
            "2. Aggressive fluid resuscitation: Early aggressive fluid resuscitation is a crucial component of sepsis management in ICUs. Older practices focused on maintaining mean arterial pressure (MAP) above 65 mmHg, while current protocols prioritize maintaining a higher MAP of 70-80 mmHg to reduce the risk of fluid overload and improve organ perfusion.\n",
            "3. vasopressor use: Older practices often relied on norepinephrine as the primary vasopressor, while current protocols incorporate a range of vasopressors, including dopamine and vasopressin, to tailor therapy to individual patients based on their hemodynamic needs.\n",
            "4. Antibiotic therapy: Earlier practices often relied on broad-spectrum antibiotics with delayed administration, while current protocols prioritize prompt initiation of targeted antibiotics based on the suspected pathogen and severity of sepsis. This approach reduces the risk of antibiotic resistance and minimizes unnecessary exposure to broad-spectrum agents.\n",
            "5. Steroid use: Older practices often included steroids in the management of sepsis, while current protocols recognize that steroids have limited evidence supporting their use in sepsis and avoid their routine use.\n",
            "6. Hemodynamic monitoring: Older practices relied on mean arterial pressure (MAP) as the primary hemodynamic parameter, while current protocols incorporate more advanced monitoring techniques, such as pulse pressure variation (PPV), to assess organ perfusion and identify fluid responsiveness.\n",
            "7. Resuscitation strategies for hypotension: Older practices often relied on a \"titrated\" approach to resuscitate patients with hypotension, while current protocols prioritize early recognition of hypotension and prompt administration of vasopressors and fluids based on the patient's response.\n",
            "8. Management of organ dysfunction: Older practices often focused solely on supporting vital organs, while current protocols recognize the importance of addressing organ dysfunction across\n",
            "============================================================\n",
            "\n",
            "=== Combo 4 – Protocol Checklist ===\n",
            " Sure! Here is a comprehensive checklist outlining the protocols and interventions for managing sepsis in a critical care unit (ICU):\n",
            "\n",
            "Diagnosis:\n",
            "\n",
            "1. Confirm the presence of systemic inflammatory response syndrome (SIRS) criteria or Sequential Organ Failure Assessment (SOFA) score ≥2, indicating severe organ dysfunction.\n",
            "\n",
            "Resuscitation and stabilization:\n",
            "\n",
            "1. Administer fluid resuscitation according to protocols based on patient's weight, age, and clinical status.\n",
            "2. Manage vasopressor therapy using dopamine or norepinephrine as needed for hypotension (SBP ≤90 mmHg).\n",
            "3. Provide oxygen therapy with non-rebreather mask at a flow rate of 6–8 liters/minute, titrating to maintain PaO2 >100 torr.\n",
            "4. Initiate broad-spectrum antibiotics effective against likely pathogens based on local epidemiology and patient's clinical status (e.g., cefotaxime or ceftriaxone for gram-negative bacteria, vancomycin for methicillin-resistant Staphylococcus aureus [MRSA]).\n",
            "5. Monitor temperature closely; treat hypothermia with passive warming measures (e.g., blankets) or active cooling therapy if indicated (e.g., ice packs).\n",
            "6. Manage pain using sedation and analgesic protocols, adjusted according to patient's level of consciousness and comfort.\n",
            "7. Provide early mobilization/physical therapy once the patient is hemodynamically stable for at least 48 hours (e.g.,\n",
            "============================================================\n",
            "\n",
            "=== Combo 5 – Teaching Style Explanation ===\n",
            " Hey there, junior medical resident! Let's talk about managing sepsis in the ICU. Sepsis is a serious infection that can quickly become life-threatening, so it's super important that we take it seriously and manage it promptly.\n",
            "First things first, we need to identify the source of the infection. Is it pneumonia? UTI? Something else? Once we know where the infection is coming from, we can start treating it.\n",
            "Next, we need to check the patient's vital signs. Are they stable? Do they have a fever? Are they tachycardic or tachypneic? We need to keep an eye on these signs and make sure they don't get worse.\n",
            "Now, let's talk about fluids. Sepsis can cause dehydration, so we need to make sure the patient is getting enough fluids to stay hydrated. But we also don't want to overload them with too much fluid, so we need to monitor their fluid status closely.\n",
            "Another important thing to consider is the patient's blood pressure. Sepsis can cause a drop in blood pressure, which can lead to organ failure. So, we need to keep an eye on the patient's blood pressure and make sure it stays within a normal range.\n",
            "Next, let's talk about antibiotics. We need to give the patient the right antibiotics to treat the infection, but we also need to be careful not to overuse them. Antibiotic resistance is a big deal, so we want to make sure we're using them wisely.\n",
            "Finally, let's talk about monitoring. We need to keep a close eye on the patient's vital signs and lab results to make sure the infection is responding to treatment. If the patient's condition starts to deteriorate, we need to be ready to make changes to their treatment plan.\n",
            "So, there you have it! Managing sepsis in the ICU is all about identifying the source of the infection, monitoring vital signs and lab results, and using antibiotics wisely. It's important to stay vigilant and make sure the patient is getting the best care possible. Got it? Awesome! Let me know if you have any questions.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRp92JQZOeff"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 1 – Medical Summary (Causes + Treatments)"
      ],
      "metadata": {
        "id": "jOHuBVZOAaXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using the first combination of parameters for hair loss queries\n",
        "def generate_llama_response_combo1(user_prompt):\n",
        "    # Create a system message instructing the LLM to provide a concise summary of causes and treatments for sudden patchy hair loss,\n",
        "    # including commonly seen scalp conditions such as alopecia areata\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Provide a concise summary of causes and treatments for sudden patchy hair loss, including commonly seen scalp conditions like alopecia areata.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model (llm) with the combined prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt to be sent to the language model\n",
        "        max_tokens=600,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.2,        # Low temperature for a more deterministic, less random response\n",
        "        top_p=0.9,              # Nucleus sampling parameter: considers tokens with cumulative probability up to 0.9\n",
        "        repeat_penalty=1.1,     # Slight penalty to discourage repeated text in the output\n",
        "        top_k=40,               # Considers only the top 40 most likely tokens for each step\n",
        "        stop=[\"INST\"],          # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False              # Exclude the input prompt from the response output\n",
        "    )\n",
        "    # Return the generated text from the response dictionary\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "N93eMmlMAceO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 2 – Step-by-Step Diagnosis and Care Plan"
      ],
      "metadata": {
        "id": "Kx8XUwz7AkBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using the second combination of parameters for hair loss queries\n",
        "def generate_llama_response_combo2(user_prompt):\n",
        "    # Create a system message instructing the LLM to outline a step-by-step diagnostic and treatment plan\n",
        "    # for a patient presenting with sudden localized hair loss on the scalp\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Outline a step-by-step diagnostic and treatment plan for a patient presenting with sudden localized hair loss on the scalp.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model (llm) with the combined prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt to be sent to the language model\n",
        "        max_tokens=768,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.4,        # Moderate temperature for some creativity while mostly factual output\n",
        "        top_p=0.85,             # Nucleus sampling: considers tokens with cumulative probability up to 0.85\n",
        "        repeat_penalty=1.0,     # No additional penalty for repeated phrases (default value)\n",
        "        top_k=60,               # Considers only the top 60 most likely tokens for each step\n",
        "        stop=[\"INST\"],          # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False              # Exclude the input prompt from the response output\n",
        "    )\n",
        "    # Return the generated text from the response dictionary\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "IAhPMAVXAnW5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 3 – Causes: Then vs. Now (Comparative)"
      ],
      "metadata": {
        "id": "0JLTc_TGAwDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using the third combination of parameters for hair loss queries\n",
        "def generate_llama_response_combo3(user_prompt):\n",
        "    # Create a system message instructing the LLM to compare historical beliefs and modern understanding\n",
        "    # of the causes and treatments for patchy hair loss, including discussion of autoimmune factors\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Compare historical beliefs and modern understanding of the causes and treatments for patchy hair loss, including autoimmune factors.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model (llm) with the combined prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt to be sent to the language model\n",
        "        max_tokens=700,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.6,        # Moderate temperature for balanced creativity and factual output\n",
        "        top_p=0.95,             # Nucleus sampling: considers tokens with cumulative probability up to 0.95\n",
        "        repeat_penalty=1.1,     # Slight penalty to discourage repeated text in the output\n",
        "        top_k=50,               # Considers only the top 50 most likely tokens for each step\n",
        "        stop=[\"INST\"],          # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False              # Exclude the input prompt from the response output\n",
        "    )\n",
        "    # Return the generated text from the response dictionary\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "3Xm53zXhA09f"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 4 – Symptom/Treatment Checklist"
      ],
      "metadata": {
        "id": "AapVHa6KA_fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using the fourth combination of parameters for hair loss queries\n",
        "def generate_llama_response_combo4(user_prompt):\n",
        "    # Create a system message instructing the LLM to provide a checklist of possible causes for sudden patchy scalp hair loss\n",
        "    # and include corresponding treatment options, both medical and lifestyle-based\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Provide a checklist of possible causes of sudden patchy scalp hair loss and corresponding treatment options, both medical and lifestyle-based.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model (llm) with the combined prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt to be sent to the language model\n",
        "        max_tokens=400,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.1,        # Very low temperature for factual, less creative output\n",
        "        top_p=0.7,              # Nucleus sampling: considers tokens with cumulative probability up to 0.7 (less diversity)\n",
        "        repeat_penalty=1.3,     # Strong penalty to discourage repeated text in the output\n",
        "        top_k=30,               # Considers only the top 30 most likely tokens for each step\n",
        "        stop=[\"INST\"],          # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False              # Exclude the input prompt from the response output\n",
        "    )\n",
        "    # Return the generated text from the response dictionary\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "2nj3XdZBBDTM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 5 – Patient-Friendly Explanation"
      ],
      "metadata": {
        "id": "W48S2_WVBMpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using the fifth combination of parameters for hair loss queries\n",
        "def generate_llama_response_combo5(user_prompt):\n",
        "    # Create a system message instructing the LLM to explain the causes and treatment options for patchy hair loss\n",
        "    # to a patient, using simple and clear language, and including advice on when to see a dermatologist\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Explain the causes and treatment options for patchy hair loss to a patient in simple, clear language, including when to see a dermatologist.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model (llm) with the combined prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The full prompt to be sent to the language model\n",
        "        max_tokens=650,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.8,        # Higher temperature for more conversational and creative output\n",
        "        top_p=1.0,              # Nucleus sampling: considers tokens with cumulative probability up to 1.0 (maximum diversity)\n",
        "        repeat_penalty=1.0,     # No penalty for repeated phrases (default value)\n",
        "        top_k=80,               # Considers only the top 80 most likely tokens for each step\n",
        "        stop=[\"INST\"],          # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False              # Exclude the input prompt from the response output\n",
        "    )\n",
        "    # Return the generated text from the response dictionary\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "i1Wdc7UJBYhD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapper Function: run_all_llama_response_combos_hairloss"
      ],
      "metadata": {
        "id": "6WNepECpBZsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to run all Llama response combinations for hair loss queries and print their outputs\n",
        "def run_all_llama_response_combos_hairloss(user_prompt):\n",
        "    # Call each of the predefined response combo functions with the user prompt,\n",
        "    # and store their outputs in a dictionary with descriptive titles as keys\n",
        "    results = {\n",
        "        \"Combo 1 – Medical Summary\": generate_llama_response_combo1(user_prompt),\n",
        "        \"Combo 2 – Step-by-Step Diagnosis/Treatment\": generate_llama_response_combo2(user_prompt),\n",
        "        \"Combo 3 – Historical vs. Modern Causes\": generate_llama_response_combo3(user_prompt),\n",
        "        \"Combo 4 – Checklist Format\": generate_llama_response_combo4(user_prompt),\n",
        "        \"Combo 5 – Patient-Friendly Explanation\": generate_llama_response_combo5(user_prompt),\n",
        "    }\n",
        "\n",
        "    # Iterate over each key-value pair in the results dictionary\n",
        "    for title, response in results.items():\n",
        "        # Print the section header, the response, and a separator line for readability\n",
        "        print(f\"\\n=== {title} ===\\n{response}\\n{'=' * 60}\")"
      ],
      "metadata": {
        "id": "mayXDXH_Bg9B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the code"
      ],
      "metadata": {
        "id": "x1DMc1S7Bqtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the hair loss question to a variable\n",
        "question = \"What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?\"\n",
        "\n",
        "# Call the function to run all Llama response combinations for hair loss using the question as input\n",
        "run_all_llama_response_combos_hairloss(question)"
      ],
      "metadata": {
        "id": "2gliRJTiBu9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0b3468-6c75-4a27-97cb-524e49681d04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Combo 1 – Medical Summary ===\n",
            " Sudden patchy hair loss, also known as localized bald spots or alopecia areata, can be caused by a variety of factors, including:\n",
            "\n",
            "1. Autoimmune disorders: In these conditions, the immune system mistakenly attacks healthy hair follicles, leading to hair loss. Alopecia areata is a common autoimmune disorder that causes patchy hair loss on the scalp.\n",
            "2. Hormonal imbalances: Hormonal changes during pregnancy, menopause, or thyroid disorders can cause sudden patchy hair loss.\n",
            "3. Infections: Fungal infections of the scalp, such as ringworm, can cause patchy hair loss.\n",
            "4. Traction alopecia: This condition occurs when the hair is pulled too tightly, leading to hair breakage and balding.\n",
            "5. Nutritional deficiencies: Deficiencies in iron, zinc, or other essential nutrients can cause patchy hair loss.\n",
            "6. Stress: Prolonged stress can lead to telogen effluvium, a condition where the body enters a resting phase and stops growing new hair. This can result in sudden patchy hair loss.\n",
            "7. Genetics: Inheritance plays a significant role in many cases of patchy hair loss.\n",
            "\n",
            "Treatments for sudden patchy hair loss depend on the underlying cause, but may include:\n",
            "\n",
            "1. Medications: Corticosteroids, immunomodulators, and retinoids are commonly used to treat autoimmune disorders like alopecia areata.\n",
            "2. Topical treatments: Minoxidil (Rogaine) and finasteride (Propecia) can help stimulate hair growth and slow down hair loss.\n",
            "3. Hormone replacement therapy: For hormonal imbalances, hormone replacement therapy may be prescribed to restore balance.\n",
            "4. Antifungal medications: For fungal infections of the scalp, antifungal creams or oral medications may be used.\n",
            "5. Reduction of stress: Stress management techniques such as meditation, yoga, or therapy can help reduce stress and prevent telogen effluvium.\n",
            "6. Dietary changes: Addressing nutritional deficiencies through dietary changes can help improve hair growth.\n",
            "7. Hair transplantation: In some cases, hair transplantation may be recommended to restore hair growth in affected areas.\n",
            "It is important to consult a dermatologist or healthcare professional for an accurate diagnosis and appropriate treatment plan for sudden patchy hair loss.\n",
            "============================================================\n",
            "\n",
            "=== Combo 2 – Step-by-Step Diagnosis/Treatment ===\n",
            " Sure, here's a step-by-step diagnostic and treatment plan for a patient presenting with sudden localized hair loss on the scalp:\n",
            "\n",
            "Step 1: Initial Evaluation\n",
            "\n",
            "* Take a detailed medical history, including any recent illnesses, infections, or stressful events.\n",
            "* Perform a physical examination of the scalp, including visual inspection, palpation, and examination of the hair follicles.\n",
            "* Use a scalp biopsy to examine the hair follicles and rule out any underlying conditions that may be causing the hair loss, such as alopecia areata, folliculitis, or tinea capitis.\n",
            "* Order blood tests to check for any underlying medical conditions that may be contributing to the hair loss, such as thyroid disorders, anemia, or autoimmune diseases.\n",
            "\n",
            "Step 2: Diagnostic Tests\n",
            "\n",
            "* Conduct a hair pull test to assess the degree of hair loss and rule out conditions such as telogen effluvium, which is characterized by excessive hair shedding due to hormonal changes.\n",
            "* Perform a scalp skin scraping to diagnose conditions such as psoriasis or eczema, which can cause hair loss.\n",
            "* Use a trichogram to assess the health of the hair shaft and identify any abnormalities, such as breakage or thinning.\n",
            "\n",
            "Step 3: Treatment Plan\n",
            "\n",
            "* Based on the results of the diagnostic tests, develop a treatment plan that may include:\n",
            "\t+ Medications: Minoxidil (Rogaine) or finasteride (Propecia) may be prescribed to promote hair growth and slow down hair loss.\n",
            "\t+ Corticosteroids: Injected or topical corticosteroids may be used to treat conditions such as alopecia areata or discoid lupus.\n",
            "\t+ Antibiotics: If the hair loss is caused by a bacterial infection, antibiotics may be prescribed.\n",
            "\t+ Hair transplantation: In cases of severe hair loss, hair transplantation may be considered.\n",
            "\t+ Lifestyle modifications: Recommendations may be made to improve overall health and well-being, such as reducing stress, improving sleep, and maintaining a balanced diet.\n",
            "\n",
            "Step 4: Monitoring and Follow-up\n",
            "\n",
            "* Schedule regular follow-up appointments to monitor the patient's progress and adjust the treatment plan as needed.\n",
            "* Encourage the patient to keep a hair loss journal to track the progression of the hair loss and any changes in their treatment plan.\n",
            "* Encourage the patient to report any changes in their overall health or any new symptoms to their primary care physician or dermatologist.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "\n",
            "=== Combo 3 – Historical vs. Modern Causes ===\n",
            " Patchy hair loss, also known as alopecia areata, has been a topic of interest for centuries. In ancient times, people believed that this condition was caused by supernatural forces or evil spirits. However, modern understanding of the causes and treatments for patchy hair loss have evolved significantly over time. Here's a comparison of historical beliefs and modern understanding of the causes and treatments for patchy hair loss:\n",
            "Historical Beliefs:\n",
            "1. Supernatural causes: In ancient cultures, people believed that patchy hair loss was caused by supernatural forces or evil spirits. For example, in ancient Egypt, it was believed that the gods were responsible for causing hair loss.\n",
            "2. Nutritional deficiencies: In ancient Greece and Rome, people believed that patchy hair loss could be caused by a lack of essential nutrients in the diet. They would often treat the condition by consuming more foods rich in iron, copper, and zinc.\n",
            "3. Hormonal imbalances: In some traditional cultures, people believed that hormonal imbalances could cause patchy hair loss. For example, in ancient India, it was believed that an imbalance of the doshas (body humors) could lead to hair loss.\n",
            "Modern Understanding:\n",
            "1. Autoimmune factors: Modern research has shown that patchy hair loss is often caused by autoimmune factors. In autoimmune alopecia areata, the immune system mistakenly attacks healthy hair follicles, leading to hair loss.\n",
            "2. Genetics: While genetics play a role in some cases of patchy hair loss, it is not the sole cause for most people.\n",
            "3. Hormonal imbalances: Hormonal changes can trigger patchy hair loss, especially during pregnancy, menopause, or thyroid disorders. However, hormonal imbalances are not the primary cause of the condition.\n",
            "4. Stress: High stress levels have been linked to an increased risk of developing patchy hair loss. This may be due to the impact of stress on the immune system and inflammation in the body.\n",
            "5. Medications: Certain medications, such as those used to treat depression, high blood pressure, or cancer, can cause patchy hair loss as a side effect.\n",
            "Treatments:\n",
            "1. Corticosteroid injections or creams: These are effective in treating mild to moderate patchy hair loss by suppressing the immune system and reducing inflammation.\n",
            "2. Minoxidil (Rogaine): This topical solution can help stimulate hair growth and slow down hair loss. It is applied directly to the affected area and is available over-the-counter.\n",
            "3. Anthralin: This medication is used to treat moderate to severe patchy hair loss by reducing inflammation and suppressing the immune system.\n",
            "4. Phototherapy: Exposure to specific wavelengths of light, such as UVB or narrowband UVB, can help stimulate hair growth and reduce inflammation.\n",
            "5. Hair transplantation: This surgical procedure involves moving healthy hair follicles from one part of the scal\n",
            "============================================================\n",
            "\n",
            "=== Combo 4 – Checklist Format ===\n",
            " Sure! Here's a comprehensive list of potential causes of sudden patchy scalp hair loss along with their associated treatments: \n",
            "Causes of Sudden Patchy Scalp Hair Loss:  1. Alopecia Areata - An autoimmune disorder that leads to unexpected hair loss on the scalp, face or body. Treatment options include topical corticosteroids, injectable steroids and immunotherapy. \n",
            "2. Telogen Effluvium- A condition where there is an abrupt increase in telogen (resting) follicles leading to excessive hair shedding. This can be caused by physical or emotional stress, hormonal changes, iron deficiency anemia and other medical conditions Treatment options include addressing the underlying cause of Telogen Effluvium as well as using minoxidil (Rogaine) lotion to stimulate hair growth. \n",
            "3. Traction Alopecia - A form of alopecia caused by constant pulling or tension on the hair follicles, usually due to tight hairstyles such as braids, ponytails and cornrows Treatment options include changing one's hairstyle and using topical corticosteroid creams. \n",
            "4. Folliculitis - An infection of the hair follicle that can lead to sudden patchy scalp hair loss due to inflammation or bacterial overgrowth Treatment options include antibiotics, warm compresses and topical corticosteroids for reducing swelling and promoting healing. \n",
            "5. Fungal Infections - Certain fungi can infect the scalp leading to patchy hair loss due to excessive itching or flaking Treatment options include antifungals such as keto\n",
            "============================================================\n",
            "\n",
            "=== Combo 5 – Patient-Friendly Explanation ===\n",
            " Sure, I'd be happy to help you understand the causes and treatment options for patchy hair loss in a simple and clear manner.\n",
            "Causes of Patchy Hair Loss:\n",
            "Patchy hair loss, also known as alopecia areata, can be caused by a variety of factors, including:\n",
            "1. Autoimmune disorders: In this condition, the immune system mistakenly attacks healthy hair follicles, leading to hair loss.\n",
            "2. Hormonal imbalances: Hormonal fluctuations during pregnancy, menopause, or thyroid disorders can cause patchy hair loss.\n",
            "3. Infections: Fungal infections of the scalp, such as ringworm, can cause patchy hair loss.\n",
            "4. Traction alopecia: This type of hair loss is caused by constant pulling or tension on the hair shaft, leading to hair follicle damage.\n",
            "5. Nutritional deficiencies: Deficiencies in iron, zinc, or other essential nutrients can cause patchy hair loss.\n",
            "Treatment Options for Patchy Hair Loss:\n",
            "The treatment options for patchy hair loss depend on the underlying cause. Here are some possible treatment options:\n",
            "1. Topical corticosteroids: These medications can help reduce inflammation and promote hair growth.\n",
            "2. Minoxidil: This medication is applied directly to the scalp and can help stimulate hair growth and slow down hair loss.\n",
            "3. Anthralin: This medication can help reduce inflammation and promote hair growth.\n",
            "4. Psoralen: This medication can help reduce inflammation and promote hair growth.\n",
            "5. Phototherapy: Exposure to specific wavelengths of light can help stimulate hair growth and reduce inflammation.\n",
            "6. Wigs or hairpieces: For individuals with extensive hair loss, these can be a cosmetic solution to cover up bald patches.\n",
            "7. Platelet-rich plasma (PRP) therapy: This treatment involves injecting platelet-rich plasma into the scalp to stimulate hair growth.\n",
            "8. Hair transplantation: This procedure involves moving healthy hair follicles from one part of the scalp to another to fill in bald patches.\n",
            "When to See a Dermatologist:\n",
            "If you are experiencing patchy hair loss, it is essential to consult a dermatologist to determine the underlying cause and develop an appropriate treatment plan. Here are some situations where you should seek medical attention:\n",
            "1. Sudden or rapid hair loss: If you are experiencing sudden or rapid hair loss, it could be a sign of an underlying medical condition that requires prompt treatment.\n",
            "2. Hair loss that is spreading: If the bald patches are spreading or increasing in size, it could be a sign of a more severe condition that requires prompt attention.\n",
            "3. Hair loss that is accompanied by other\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA45zwyUOefg"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Combination 1 – Medical Summary (Generalized + Structured)"
      ],
      "metadata": {
        "id": "_gi8FTc2CnNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate an LLM response using the first combination of parameters for TBI treatment queries\n",
        "def generate_llama_response_combo1(user_prompt):\n",
        "    # Create a system message instructing the LLM to provide a concise overview of treatments for traumatic brain injury (TBI),\n",
        "    # including both short-term and long-term interventions\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Provide a concise overview of treatments for traumatic brain injury (TBI), covering both short-term and long-term interventions.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model (llm) with the combined prompt and a specific set of generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,          # The complete prompt to be sent to the language model\n",
        "        max_tokens=600,         # Set the maximum number of tokens for the generated response\n",
        "        temperature=0.2,        # Low temperature for more focused and deterministic output\n",
        "        top_p=0.9,              # Nucleus sampling: considers tokens with cumulative probability up to 0.9\n",
        "        repeat_penalty=1.1,     # Slight penalty to discourage repeated text in the output\n",
        "        top_k=40,               # Considers only the top 40 most likely tokens at each step\n",
        "        stop=[\"INST\"],          # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False              # Exclude the input prompt from the response output\n",
        "    )\n",
        "    # Return the generated text from the response dictionary\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "u1cNkaAwCyJl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 2 - Step-by-Step Treatment Protocol"
      ],
      "metadata": {
        "id": "w84zDFelC3Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo2(user_prompt):\n",
        "    # Define the system message that instructs the LLM to provide a step-by-step management plan for brain tissue injury\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Describe the step-by-step management plan for a patient with brain tissue injury, from acute care to rehabilitation and long-term support.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user prompt and the system message to create the full prompt for the LLM\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the constructed prompt and specified generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The prompt to be given to the LLM\n",
        "        max_tokens=768,          # The maximum number of tokens to generate in the response\n",
        "        temperature=0.4,         # Controls randomness: lower values make output more focused and deterministic\n",
        "        top_p=0.85,              # Nucleus sampling: considers tokens with cumulative probability up to 0.85\n",
        "        repeat_penalty=1.0,      # Penalty for repeated phrases; 1.0 means no extra penalty\n",
        "        top_k=60,                # Considers only the top 60 most likely tokens at each step\n",
        "        stop=[\"INST\"],           # Stop generating if the string \"INST\" is encountered\n",
        "        echo=False               # Do not include the original prompt in the output\n",
        "    )\n",
        "    # Extract and return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "5uhJ3oEkEDJW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 3 – Advances in Brain Injury Treatment (Comparative)"
      ],
      "metadata": {
        "id": "A5nT3WhBESK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo3(user_prompt):\n",
        "    # Define the system message that tells the LLM to compare traditional and modern approaches to treating traumatic brain injuries,\n",
        "    # with an emphasis on innovations in neurorehabilitation and neurosurgery\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Compare traditional and modern approaches to treating traumatic brain injuries, highlighting innovations in neurorehabilitation and neurosurgery.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt with the system message to create the full prompt for the LLM\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the constructed prompt and specific generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The full prompt string to provide context and instructions to the LLM\n",
        "        max_tokens=700,          # The maximum number of tokens allowed in the generated response\n",
        "        temperature=0.6,         # A moderate temperature for balanced creativity and determinism\n",
        "        top_p=0.95,              # Nucleus sampling: considers tokens with cumulative probability up to 0.95\n",
        "        repeat_penalty=1.1,      # Slight penalty to discourage repeated text in the output\n",
        "        top_k=50,                # Considers only the top 50 most likely tokens at each generation step\n",
        "        stop=[\"INST\"],           # Stops generation if the string \"INST\" is encountered\n",
        "        echo=False               # Do not include the input prompt in the generated output\n",
        "    )\n",
        "    # Extract and return the text generated by the LLM from the response object\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "0YWl4P-0EWtQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 4  – Checklist Format (Structured and Actionable)"
      ],
      "metadata": {
        "id": "uYa_z3G2Ed-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo4(user_prompt):\n",
        "    # Define the system message instructing the LLM to provide a checklist of treatment steps and supportive therapies\n",
        "    # for patients with brain injuries, organized by severity and recovery stage\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Provide a checklist of treatment steps and supportive therapies for patients with brain injuries, categorized by severity and stage of recovery.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the constructed prompt and specified parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The full prompt to send to the LLM\n",
        "        max_tokens=400,          # The maximum number of tokens to generate in the response\n",
        "        temperature=0.1,         # Low temperature for highly focused and deterministic output\n",
        "        top_p=0.7,               # Nucleus sampling: considers tokens with cumulative probability up to 0.7\n",
        "        repeat_penalty=1.3,      # Strong penalty to reduce repeated phrases in the output\n",
        "        top_k=30,                # Considers only the top 30 most likely tokens at each step\n",
        "        stop=[\"INST\"],           # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False               # Do not include the original prompt in the generated output\n",
        "    )\n",
        "    # Extract and return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "i-_zmTqMEk09"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 5 – Patient-Centered Education Style"
      ],
      "metadata": {
        "id": "4Ui2_6Y7Erdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo5(user_prompt):\n",
        "    # Define the system message instructing the LLM to explain brain injury treatments in simple, clear language\n",
        "    # for a non-medical audience, and include information about recovery and available support options\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Explain brain injury treatments in clear, simple terms for a non-medical audience, including what recovery might look like and support options.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the constructed prompt and specified generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The complete prompt string for the LLM\n",
        "        max_tokens=650,          # Maximum number of tokens to generate for the response\n",
        "        temperature=0.8,         # Higher temperature for more conversational and creative output\n",
        "        top_p=1.0,               # Nucleus sampling: considers tokens with cumulative probability up to 1.0 (maximum diversity)\n",
        "        repeat_penalty=1.0,      # Default penalty; does not discourage repetition\n",
        "        top_k=80,                # Considers only the top 80 most likely tokens at each generation step\n",
        "        stop=[\"INST\"],           # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False               # Do not include the input prompt in the model's output\n",
        "    )\n",
        "    # Extract and return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "u96i-g3DExZ2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Wrapper Function: run_all_llama_response_combos_braininjury"
      ],
      "metadata": {
        "id": "nAIYrlSeE-vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all_llama_response_combos_braininjury(user_prompt):\n",
        "    # Call each of the predefined brain injury response combo functions with the user prompt,\n",
        "    # and store their outputs in a dictionary with descriptive titles as keys\n",
        "    results = {\n",
        "        \"Combo 1 – Medical Summary\": generate_llama_response_combo1(user_prompt),       # Concise overview of TBI treatments\n",
        "        \"Combo 2 – Step-by-Step Protocol\": generate_llama_response_combo2(user_prompt), # Step-by-step management plan\n",
        "        \"Combo 3 – Advances in Treatment\": generate_llama_response_combo3(user_prompt), # Traditional vs. modern approaches and innovations\n",
        "        \"Combo 4 – Checklist Format\": generate_llama_response_combo4(user_prompt),      # Checklist of treatments by severity and stage\n",
        "        \"Combo 5 – Patient Education Style\": generate_llama_response_combo5(user_prompt),# Simple explanation for patients/non-medical audience\n",
        "    }\n",
        "\n",
        "    # Iterate over each key-value pair in the results dictionary\n",
        "    for title, response in results.items():\n",
        "        # Print the section header, the generated response, and a separator line for clarity\n",
        "        print(f\"\\n=== {title} ===\\n{response}\\n{'=' * 60}\")"
      ],
      "metadata": {
        "id": "GHrFDwFgFBGr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the code"
      ],
      "metadata": {
        "id": "e-PVvJOrFICt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the brain injury treatment question to a variable\n",
        "question = \"What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?\"\n",
        "\n",
        "# Call the function to run all Llama response combinations for brain injury using the question as input\n",
        "run_all_llama_response_combos_braininjury(question)"
      ],
      "metadata": {
        "id": "K6JgNi0rFLO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a07d51c-285d-4169-c91f-4be0cea40204"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Combo 1 – Medical Summary ===\n",
            " Traumatic brain injury (TBI) is a complex and multifaceted condition that requires a comprehensive treatment approach encompassing various interventions. The following is an overview of short-term and long-term treatments for TBI, including their goals, methods, and expected outcomes:\n",
            "Short-Term Treatments (0-3 months):\n",
            "1. Acute Management: Immediate management of TBI involves stabilizing the patient's vital signs, controlling bleeding, and addressing any life-threatening complications. This phase focuses on preventing further damage and ensuring the patient's safety.\n",
            "2. Monitoring and Observation: Patients with mild to moderate TBI are closely monitored for changes in their condition, including neurological symptoms, cognitive function, and behavioral alterations. Regular assessments help identify any deterioration or improvement.\n",
            "3. Medications: Various medications may be prescribed to manage symptoms such as pain, agitation, anxiety, and depression. These may include sedatives, anti-anxiety drugs, and antidepressants.\n",
            "4. Rehabilitation Therapy: Physical therapy, occupational therapy, and speech therapy are initiated to help patients regain lost functions and abilities. These therapies focus on improving cognitive, motor, and communication skills.\n",
            "Long-Term Treatments (>3 months):\n",
            "1. Cognitive Rehabilitation: This phase aims to improve cognitive function, including attention, memory, problem-solving, and decision-making abilities. Cognitive rehabilitation may involve various techniques, such as cognitive training programs, cognitive behavioral therapy (CBT), and neuropsychological rehabilitation.\n",
            "2. Behavioral Therapy: Patients with TBI may exhibit behavioral changes, including irritability, aggression, and emotional instability. Behavioral therapy helps manage these symptoms through techniques such as cognitive-behavioral therapy (CBT), dialectical behavior therapy (DBT), and psychodynamic therapy.\n",
            "3. Neuropsychological Rehabilitation: This phase focuses on improving the patient's ability to perform daily activities, manage their emotions, and interact with others. Neuropsychological rehabilitation may involve various techniques, such as cognitive training programs, behavioral therapy, and social skills training.\n",
            "4. Supportive Care: This includes managing chronic symptoms, providing emotional support, and addressing any psychosocial issues that may arise. Supportive care may involve counseling, psychotherapy, and family therapy.\n",
            "5. Ass\n",
            "============================================================\n",
            "\n",
            "=== Combo 2 – Step-by-Step Protocol ===\n",
            " Step 1: Acute Care (0-1 week)\n",
            "\n",
            "* Immediate assessment and stabilization of the patient's condition, including neurological examination, laboratory tests, and imaging studies.\n",
            "* Management of associated injuries, such as head trauma, fractures, or bleeding.\n",
            "* Providing oxygen therapy and other life-sustaining measures as needed.\n",
            "* Initiation of medications to control swelling, pain, and seizures.\n",
            "\n",
            "Step 2: Subacute Care (1-4 weeks)\n",
            "\n",
            "* Continued monitoring of the patient's condition, including frequent neurological examinations and adjustment of medications as needed.\n",
            "* Rehabilitation therapy, including physical, occupational, and speech therapy, to help the patient regain lost functions and abilities.\n",
            "* Addressing any psychological or emotional issues that may arise from the injury.\n",
            "* Family support and education on the patient's condition and treatment plan.\n",
            "\n",
            "Step 3: Inpatient Rehabilitation (4-12 weeks)\n",
            "\n",
            "* Intensive rehabilitation therapy, including physical, occupational, and speech therapy, to help the patient regain lost functions and abilities.\n",
            "* Addressing any cognitive, emotional, or behavioral issues that may arise from the injury.\n",
            "* Family support and education on the patient's condition and treatment plan.\n",
            "* Preparation for discharge and community reintegration.\n",
            "\n",
            "Step 4: Outpatient Rehabilitation (12 weeks-1 year)\n",
            "\n",
            "* Ongoing rehabilitation therapy, including physical, occupational, and speech therapy, to help the patient continue to regain lost functions and abilities.\n",
            "* Addressing any ongoing cognitive, emotional, or behavioral issues that may arise from the injury.\n",
            "* Family support and education on the patient's condition and treatment plan.\n",
            "* Preparation for return to work or school.\n",
            "\n",
            "Step 5: Long-term Support (1 year+ )\n",
            "\n",
            "* Ongoing support and monitoring of the patient's condition, including regular neurological examinations and adjustment of medications as needed.\n",
            "* Addressing any ongoing cognitive, emotional, or behavioral issues that may arise from the injury.\n",
            "* Providing resources and support for the patient and their family, including counseling, support groups, and home health care services.\n",
            "* Preparation for future challenges and needs.\n",
            "\n",
            "It is important to note that each patient's treatment plan will be unique and may involve a combination of these steps, with a focus on the patient's individual needs and goals. The management plan may also evolve over time as the patient's condition changes.\n",
            "============================================================\n",
            "\n",
            "=== Combo 3 – Advances in Treatment ===\n",
            " Traumatic brain injuries (TBIs) are a leading cause of disability worldwide, with approximately 1.5 million cases occurring annually in the United States alone. The traditional approach to treating TBIs has relied heavily on supportive care, such as physical therapy, occupational therapy, and speech therapy, with a focus on managing symptoms and improving quality of life. However, recent innovations in neurorehabilitation and neurosurgery have significantly improved outcomes for TBI patients.\n",
            "Modern Approaches:\n",
            "1. Neurorehabilitation: Neurorehabilitation is a multidisciplinary approach that involves a team of healthcare professionals working together to help patients recover lost cognitive, emotional, and physical function. This approach has been shown to improve outcomes for TBI patients, particularly those with mild to moderate injuries. Neurorehabilitation may include cognitive therapy, behavioral therapy, and physical therapy, as well as speech and language therapy.\n",
            "2. Neurosurgery: Advances in neurosurgical techniques have improved the ability to treat TBIs with surgical interventions. For example, minimally invasive procedures such as endovascular coiling can be used to treat intracranial injuries caused by bleeding or swelling in the brain. Additionally, innovations in implantable devices, such as deep brain stimulators, have shown promise in treating TBI-related conditions such as chronic pain and depression.\n",
            "3. Stem Cell Therapy: Stem cell therapy is a promising area of research for the treatment of TBIs. Stem cells have the ability to differentiate into different types of brain cells, which may help replace damaged or lost cells in the brain following an injury. While still in the experimental stages, stem cell therapy has shown promise in animal studies and is being investigated as a potential treatment for TBI patients.\n",
            "4. Optimizing Management of Severe Injuries: For patients with severe injuries, such as those resulting in coma or vegetative state, early and aggressive management is crucial to optimize outcomes. This includes prompt identification and treatment of secondary complications such as seizures, infections, and hydrocephalus.\n",
            "5. Advanced Imaging Techniques: Advances in imaging techniques, such as functional MRI (fMRI), diffusion tensor imaging (DTI), and magnetoencephalography (MEG), have improved the ability to diagnose and monitor TBIs. These technologies allow clinicians to assess brain function and identify areas of damage or dysfunction, which can inform treatment decisions.\n",
            "6. Personalized Medicine: With the increasing availability of genetic data and advances in computational power, personalized medicine is becoming more accessible for TBI patients. This approach involves tailoring treatments to an individual's unique genetic profile, which may help optimize outcomes and reduce adverse effects.\n",
            "7. Virtual Reality Therapy: Virtual reality (VR) therapy has shown promise in treating a range of cognitive and emotional deficits following TBI, including attention, memory, and mood regulation. VR ther\n",
            "============================================================\n",
            "\n",
            "=== Combo 4 – Checklist Format ===\n",
            "1. Acute Stage (0-3 months): \n",
            "a) Emergency medical care: Immediate attention to stabilize the patient's condition, including CPR or other life-saving interventions if necessary.\n",
            "b) Monitoring and observation: Close monitoring of vital signs, neurological function, and any changes in consciousness or cognitive status.\n",
            "c) Medications: Administered to manage symptoms such as pain, agitation, seizures, or swelling around the brain injury site.\n",
            "d) Rehabilitative therapies (physical, occupational, speech): Beginning assessment and treatment of functional deficits related to cognitive-motor impairments.\n",
            "e) Supportive care: Providing emotional support and addressing any psychological or social concerns that may arise during this critical stage.\n",
            "2. Subacute Stage (3-6 months): \n",
            "a) Continued rehabilitative therapies: Focusing on more advanced exercises to improve cognitive, motor, and functional abilities.\n",
            "b) Cognitive training: Targeted interventions aimed at improving memory, attention, problem-solving skills, or other cognitive functions affected by the injury.\n",
            "c) Behavioral therapies (e.g., counseling): Addressing emotional and behavioral changes that may result from brain damage, such as depression, anxiety, or personality shifts.\n",
            "d) Supportive care: Continued psychological support to help patients cope with the ongoing challenges of recovery.\n",
            "3. Chronic Stage (6-12 months): \n",
            "a) Rehabilitative therapies: Focusing on more specialized interventions tailored to individual needs, such as adaptive techniques for daily living or vocational retraining if necessary.\n",
            "============================================================\n",
            "\n",
            "=== Combo 5 – Patient Education Style ===\n",
            " Certainly, I'd be happy to help you understand the treatments for brain injuries in a clear and simple way!\n",
            "\n",
            "A brain injury occurs when the brain is damaged due to trauma, infection, or other factors. The injury can cause a range of symptoms, including memory loss, confusion, difficulty with communication, and changes in mood or behavior. Depending on the severity of the injury, treatment options may vary.\n",
            "\n",
            "Treatment for a brain injury may include:\n",
            "\n",
            "1. Medications: To manage symptoms such as pain, anxiety, or depression, medications may be prescribed.\n",
            "2. Rehabilitation therapy: This type of therapy helps individuals regain skills and abilities lost due to the injury. Physical therapy, occupational therapy, and speech therapy are common forms of rehabilitation therapy.\n",
            "3. Cognitive therapy: This type of therapy helps individuals manage cognitive impairments, such as memory loss or difficulty with problem-solving.\n",
            "4. Lifestyle changes: Changes to one's lifestyle can help manage symptoms and improve overall brain health. This may include getting regular exercise, eating a healthy diet, and getting enough sleep.\n",
            "5. Surgery: In some cases, surgery may be necessary to relieve pressure on the brain or repair damaged tissue.\n",
            "\n",
            "Recovery from a brain injury can be a long and challenging process. It's important to remember that recovery is not always linear and may take time. Some individuals may experience significant improvement, while others may experience ongoing symptoms. It's important to work closely with medical professionals to develop a treatment plan that meets one's individual needs and goals.\n",
            "\n",
            "It's also important to remember that brain injury can have a significant impact on the individual and their loved ones. Support from family, friends, and mental health professionals can be crucial during this time. Joining a support group or seeking counseling can help individuals cope with the emotional challenges of brain injury.\n",
            "\n",
            "In summary, treatments for brain injuries may include medications, rehabilitation therapy, cognitive therapy, lifestyle changes, and surgery. Recovery from a brain injury can be a long and challenging process, but with the right treatment and support, individuals can achieve meaningful improvements in their brain function and overall quality of life.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXxiSuBOefg"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combinatiion 1 – Medical Summary (Emergency + Recovery Focus)"
      ],
      "metadata": {
        "id": "Xmvyf3YhFl0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo1(user_prompt):\n",
        "    # Define the system message instructing the LLM to provide a concise medical summary\n",
        "    # that covers emergency response, treatment steps, and recovery considerations for a leg fracture during hiking\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Provide a concise medical summary outlining emergency response, treatment steps, and recovery considerations for a leg fracture sustained during hiking.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the prompt and the specified generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The full prompt to send to the LLM\n",
        "        max_tokens=600,          # Maximum number of tokens to generate for the response\n",
        "        temperature=0.2,         # Low temperature for focused, deterministic output\n",
        "        top_p=0.9,               # Nucleus sampling: considers tokens with cumulative probability up to 0.9\n",
        "        repeat_penalty=1.1,      # Slight penalty to discourage repeated phrases\n",
        "        top_k=40,                # Considers only the top 40 most likely tokens at each step\n",
        "        stop=[\"INST\"],           # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False               # Do not include the prompt in the output\n",
        "    )\n",
        "    # Extract and return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "c11Ia8k3FpCt"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 2 – Step-by-Step Protocol"
      ],
      "metadata": {
        "id": "hTHK20SkFuR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo2(user_prompt):\n",
        "    # Define the system message instructing the LLM to outline a step-by-step management process for a leg fracture,\n",
        "    # starting from the injury on a hiking trail, through hospital care, to recovery\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Outline the step-by-step process to manage a leg fracture from the moment of injury on a hiking trail through hospital treatment and recovery.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the constructed prompt and specified generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The complete prompt to send to the LLM\n",
        "        max_tokens=768,          # Maximum number of tokens allowed in the generated response\n",
        "        temperature=0.4,         # Moderate temperature for a balance of determinism and creativity\n",
        "        top_p=0.85,              # Nucleus sampling: considers tokens with cumulative probability up to 0.85\n",
        "        repeat_penalty=1.0,      # Standard penalty for repeated text (no extra penalty)\n",
        "        top_k=60,                # Considers only the top 60 most likely tokens at each step\n",
        "        stop=[\"INST\"],           # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False               # Do not include the prompt itself in the output\n",
        "    )\n",
        "    # Extract and return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "wRgA_CD8Fy6v"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Combination 3 – Field vs. Clinical Treatment (Comparative)"
      ],
      "metadata": {
        "id": "C7ZnD3UsF5Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo3(user_prompt):\n",
        "    # Define the system message instructing the LLM to compare emergency field management of a fractured leg\n",
        "    # with in-hospital treatment and rehabilitation, highlighting differences in priorities and tools used\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Compare emergency field management of a fractured leg with in-hospital treatment and rehabilitation, including differences in priorities and tools.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the constructed prompt and specified generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The complete prompt string for the LLM\n",
        "        max_tokens=700,          # Maximum number of tokens allowed in the generated response\n",
        "        temperature=0.6,         # Moderate temperature for balanced creativity and determinism\n",
        "        top_p=0.95,              # Nucleus sampling: considers tokens with cumulative probability up to 0.95\n",
        "        repeat_penalty=1.1,      # Slight penalty to discourage repeated phrases in the output\n",
        "        top_k=50,                # Considers only the top 50 most likely tokens at each step\n",
        "        stop=[\"INST\"],           # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False               # Do not include the prompt itself in the output\n",
        "    )\n",
        "    # Extract and return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "VK67KsBIGBad"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combinatiion 4 – Checklist Format (Quick Reference)"
      ],
      "metadata": {
        "id": "6fE051JgGHCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo4(user_prompt):\n",
        "    # Define the system message instructing the LLM to provide a checklist of precautions,\n",
        "    # immediate treatments, and recovery steps for a person with a leg fracture sustained while hiking\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Provide a checklist of precautions, immediate treatments, and recovery steps for a person with a leg fracture sustained while hiking.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the constructed prompt and specified generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The complete prompt to send to the LLM\n",
        "        max_tokens=400,          # Maximum number of tokens to generate for the response\n",
        "        temperature=0.1,         # Low temperature for focused and deterministic output\n",
        "        top_p=0.7,               # Nucleus sampling: considers tokens with cumulative probability up to 0.7\n",
        "        repeat_penalty=1.3,      # Strong penalty to reduce repeated phrases in the output\n",
        "        top_k=30,                # Considers only the top 30 most likely tokens at each generation step\n",
        "        stop=[\"INST\"],           # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False               # Do not include the prompt itself in the output\n",
        "    )\n",
        "    # Extract and return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "iEKabLsFGL6U"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combination 5 – Patient-Friendly Education Style"
      ],
      "metadata": {
        "id": "aEPzpcLRGTxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llama_response_combo5(user_prompt):\n",
        "    # Define the system message instructing the LLM to explain, in simple, clear language,\n",
        "    # what to do if someone breaks their leg while hiking, and what to expect during healing and recovery\n",
        "    system_message = \"\"\"\n",
        "    [INST]<<SYS>> Explain in simple, clear language what someone should do if they break their leg while hiking, and what to expect during healing and recovery.<</SYS>>[/INST]\n",
        "    \"\"\"\n",
        "    # Combine the user's prompt and the system message into a single prompt string\n",
        "    prompt = f\"{user_prompt}\\n{system_message}\"\n",
        "    # Call the language model with the constructed prompt and specified generation parameters\n",
        "    response = llm(\n",
        "        prompt=prompt,           # The full prompt string for the LLM\n",
        "        max_tokens=650,          # Maximum number of tokens to generate for the response\n",
        "        temperature=0.8,         # Higher temperature for a more conversational and creative output\n",
        "        top_p=1.0,               # Nucleus sampling: considers tokens with cumulative probability up to 1.0 (maximum diversity)\n",
        "        repeat_penalty=1.0,      # Standard penalty for repeated text (no extra penalty)\n",
        "        top_k=80,                # Considers only the top 80 most likely tokens at each generation step\n",
        "        stop=[\"INST\"],           # Stops generating if the string \"INST\" appears in the output\n",
        "        echo=False               # Do not include the prompt itself in the output\n",
        "    )\n",
        "    # Extract and return the generated text from the model's response\n",
        "    return response[\"choices\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "hCQubzN3GZHq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapper Function: run_all_llama_response_combos_legfracture"
      ],
      "metadata": {
        "id": "iweHXG9pGgsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all_llama_response_combos_legfracture(user_prompt):\n",
        "    # Call each of the predefined leg fracture response combo functions with the user prompt,\n",
        "    # and store their outputs in a dictionary with descriptive titles as keys\n",
        "    results = {\n",
        "        \"Combo 1 – Medical Summary\": generate_llama_response_combo1(user_prompt),        # Concise medical summary for leg fracture during hiking\n",
        "        \"Combo 2 – Step-by-Step Protocol\": generate_llama_response_combo2(user_prompt),  # Step-by-step management process\n",
        "        \"Combo 3 – Field vs. Hospital Care\": generate_llama_response_combo3(user_prompt),# Compare field and hospital/rehab care\n",
        "        \"Combo 4 – Checklist Format\": generate_llama_response_combo4(user_prompt),       # Checklist of precautions and treatments\n",
        "        \"Combo 5 – Patient Education Style\": generate_llama_response_combo5(user_prompt),# Simple explanation for patients/non-medical audience\n",
        "    }\n",
        "\n",
        "    # Iterate over each key-value pair in the results dictionary\n",
        "    for title, response in results.items():\n",
        "        # Print the section header, the generated response, and a separator line for clarity\n",
        "        print(f\"\\n=== {title} ===\\n{response}\\n{'=' * 60}\")"
      ],
      "metadata": {
        "id": "0VFLGo8-GkAv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the code"
      ],
      "metadata": {
        "id": "eqd_ymsqGrFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the leg fracture scenario question to a variable\n",
        "question = \"What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?\"\n",
        "\n",
        "# Call the function to run all Llama response combinations for leg fracture using the question as input\n",
        "run_all_llama_response_combos_legfracture(question)"
      ],
      "metadata": {
        "id": "trggXct_GuBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3669374d-f024-42a2-c498-ba160944b786"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Combo 1 – Medical Summary ===\n",
            " Emergency Response:\n",
            "* Call for emergency medical services (EMS) if the person is unable to move or is experiencing severe pain.\n",
            "* Immobilize the injured leg using a splint or makeshift immobilizing device to prevent further injury.\n",
            "* Keep the affected area at or below the level of the heart to reduce swelling.\n",
            "* Monitor vital signs and provide basic first aid as needed.\n",
            "Treatment Steps:\n",
            "* Transport the person to a medical facility for proper evaluation and treatment.\n",
            "* Administer pain medication, such as ibuprofen or acetaminophen, as directed by a medical professional.\n",
            "* Apply a cast or brace to immobilize the leg and promote healing.\n",
            "* Monitor for signs of infection, such as redness, swelling, or increased pain.\n",
            "* Follow up with a medical professional for further evaluation and treatment.\n",
            "Recovery Considerations:\n",
            "* Encourage the person to rest and avoid putting weight on the injured leg during the healing process.\n",
            "* Provide emotional support and reassurance throughout the recovery process.\n",
            "* Monitor progress and adjust treatment as needed based on the individual's response to therapy and healing.\n",
            "* Follow up with a medical professional for further evaluation and treatment as needed.\n",
            "In conclusion, a leg fracture sustained during hiking can be a serious injury that requires prompt medical attention. It is essential to take necessary precautions, provide appropriate treatment, and monitor the person's progress throughout their recovery to ensure proper healing and minimize potential complications.\n",
            "============================================================\n",
            "\n",
            "=== Combo 2 – Step-by-Step Protocol ===\n",
            "1. Assess the situation and call for help:\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
            "============================================================\n",
            "\n",
            "=== Combo 3 – Field vs. Hospital Care ===\n",
            " Emergency Field Management vs. In-Hospital Treatment and Rehabilitation: A Comparison for Fractured Leg Injuries\n",
            "Introduction:\n",
            "Fractures of the leg are common injuries that can occur during hiking trips, especially in remote areas where medical assistance may be delayed. In such cases, emergency field management plays a crucial role in providing immediate care and stabilizing the injury before transportation to a hospital. However, once the patient reaches a medical facility, their treatment and rehabilitation require different approaches and tools. This article compares the priorities and tools used in emergency field management with those employed in in-hospital treatment and rehabilitation for fractured leg injuries.\n",
            "Emergency Field Management:\n",
            "1. Priorities:\n",
            "a. Immobilization of the affected limb using splints or casts to prevent further damage and promote healing.\n",
            "b. Control of bleeding through direct pressure or tourniquet application, if necessary.\n",
            "c. Pain management with analgesia and sedation, as needed.\n",
            "d. Transportation to a medical facility as soon as possible for further evaluation and treatment.\n",
            "2. Tools:\n",
            "a. Portable splints or improvised splints made from available materials.\n",
            "b. Trauma kits containing basic surgical supplies like gauze, bandages, and tape.\n",
            "c. Tourniquets or hemostatic devices like QuikClot for bleeding control.\n",
            "d. Pain management medication like morphine or fentanyl.\n",
            "3. Considerations:\n",
            "a. Limited medical resources in remote areas may require creative problem-solving and improvisation.\n",
            "b. The patient's condition should be regularly monitored for signs of shock, infection, or other complications.\n",
            "c. In some cases, surgical intervention may be necessary to realign bones or repair damaged tissue.\n",
            "In-Hospital Treatment and Rehabilitation:\n",
            "1. Priorities:\n",
            "a. Evaluation of the fracture's severity and type, including X-ray or CT scan imaging.\n",
            "b. Surgical intervention to realign bones, repair damaged tissue, or stabilize the joint.\n",
            "c. Management of associated injuries like soft tissue damage or nerve damage.\n",
            "d. Preparation for postoperative care and rehabilitation.\n",
            "2. Tools:\n",
            "a. Advanced imaging technologies like MRI or ultrasound for detailed fracture assessment.\n",
            "b. Surgical instruments and implants, such as plates, screws, or rods, depending on the fracture type.\n",
            "c. Physical therapy equipment and modalities, including weights, resistance bands, and electrical stimulation.\n",
            "d. Pain management medication and other anesthetics for postoperative care.\n",
            "3. Considerations:\n",
            "a. Detailed evaluation of the patient's overall health status to guide treatment decisions.\n",
            "b. Coordination with orthopedic specialists or physical therapists to ensure optimal rehabilitation strategies.\n",
            "c. Monitoring for potential complications like infection, nerve damage, or blood cl\n",
            "============================================================\n",
            "\n",
            "=== Combo 4 – Checklist Format ===\n",
            " Sure! Here is a comprehensive checklist of precautions, immediate treatment measures, and recovery steps that should be taken into consideration when dealing with a leg fracture sustained during a hiking trip:  Precautionary Measures:  1. Call for emergency medical assistance immediately if the person experiences severe pain or difficulty moving their leg after the injury.\n",
            "2. Keep the affected limb immobile and at heart level to prevent further damage until proper treatment can be administered. 3. Apply a splint or brace around the injured area, securing it in place with bandages if necessary, to stabilize the fracture site.  4. Remove any jewelry that could interfere with medical care and make sure the person is wearing loose-fitting clothing for easy accessibility of their affected limb. 5. Check the person's vital signs regularly (pulse, breathing rate, temperature) to ensure they are stable and receiving proper treatment promptly if necessary.  \n",
            "Immediate Treatment Measures:   1. Immobilize the injured leg using a splint or cast that is properly fitted by medical professionals for at least 6-8 weeks after injury to allow adequate healing time, depending on severity of fracture and individual circumstances.  2. Administer pain medication (such as ibuprofen) according to the recommended dosage instructions provided with each prescription or over-the counter drug labeling for proper management of discomfort during recovery process. 3. Monitor blood sugar levels regularly if diabetes is present, ensuring that they remain within a healthy range throughout treatment and post-treatment care phases to prevent complications from developing due to uncontrolled glucose fluctuations (elevated or low).  4. Keep the affected limb elevated\n",
            "============================================================\n",
            "\n",
            "=== Combo 5 – Patient Education Style ===\n",
            " If a person breaks their leg while hiking, there are several steps they should take immediately to ensure proper care and recovery. Here are the necessary precautions and treatment steps to consider:\n",
            "\n",
            "  1. Assess the injury: The first step is to assess the severity of the injury. Check for any other injuries as well, such as broken bones or internal bleeding. If the person is in pain, try to keep them calm and still to prevent further injury.\n",
            "\n",
            "  2. Call for help: If the injury is severe, call 911 or contact emergency services immediately. If the injury is minor, try to find a way to communicate with the nearest town or village for help.\n",
            "\n",
            "  3. Immobilize the leg: Use a splint or a makeshift one to immobilize the broken leg. This will help reduce swelling and pain. Make sure the splint is not too tight and causes circulation problems.\n",
            "\n",
            "  4. Apply ice: Apply ice packs to the injured area to reduce swelling and pain. Wrap the ice in a cloth to avoid direct contact with the skin.\n",
            "\n",
            "  5. Elevate the leg: Elevate the injured leg above the level of the heart to reduce swelling and bleeding.\n",
            "\n",
            "  6. Administer pain medication: If the person is in severe pain, administer pain medication such as ibuprofen or acetaminophen. However, never give aspirin to someone who has broken a bone without medical advice.\n",
            "\n",
            "  7. Keep the person warm: Keep the person warm and comfortable. Hypothermia can set in quickly in cold weather, so keep them covered and out of the wind.\n",
            "\n",
            "  8. Transport to a medical facility: If the injury is severe, transport the person to a medical facility as soon as possible. If the injury is minor, try to get them to a hospital within 24 hours for proper treatment and care.\n",
            "\n",
            "  9. Follow medical advice: Follow the advice of medical professionals regarding the person's care and recovery. They will provide specific instructions on how to manage the injury and promote healing.\n",
            "\n",
            "  10. Be patient: Recovery from a broken leg can take time. Be patient and follow the treatment plan provided by medical professionals to ensure proper healing and recovery.\n",
            "\n",
            "   During healing and recovery, the person may experience several symptoms and side effects, including:\n",
            "\n",
            "  1. Pain: Broken bones can be very painful, and pain management is crucial during healing and recovery. Medication and other treatments can help manage pain.\n",
            "\n",
            "  2. Swelling: Swelling is common after a broken leg, and it can take time to reduce. Elevating the leg and applying ice can help reduce swelling.\n",
            "\n",
            "  3. Limited mobility: A broken leg can limit mobility, and it's important to follow a rehabilitation plan to regain strength and mobility.\n",
            "\n",
            "  4. Infection:\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation for RAG"
      ],
      "metadata": {
        "id": "t_O1PGdNO2M9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTpWESc53dL9"
      },
      "source": [
        "### Loading the data file provided"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to the google drive"
      ],
      "metadata": {
        "id": "IYwbGC0QIMZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3q_GcUicJqp",
        "outputId": "6b2b4023-0621-47a8-d56a-b610a613513b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the file"
      ],
      "metadata": {
        "id": "1ktEITWzIRqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Corrected path to access the file from Google Drive\n",
        "pdf_file = \"medical_diagnosis_manual.pdf\"\n",
        "loader = PyMuPDFLoader(pdf_file)\n"
      ],
      "metadata": {
        "id": "ybj2cEnzRSXq"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffj0ca3eZT4u"
      },
      "source": [
        "### Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9weTDzMxRRS"
      },
      "source": [
        "#### Checking the first 5 pages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loader.load()\n",
        "for i in range(min(5, len(documents))):\n",
        "    # Print the page number from the document's metadata\n",
        "    print(f\"--- Page {documents[i].metadata['page']} ---\")\n",
        "    # Print the first 500 characters of the page content for preview\n",
        "    print(documents[i].page_content[:500])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AOY9c_deJl9",
        "outputId": "7c341601-c949-42bd-be31-d07e92d55fd2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Page 0 ---\n",
            "vamseekrishna11@hotmail.com\n",
            "RSKN0VL9FW\n",
            "for personal use by vamseekrishna11@\n",
            "shing the contents in part or full is liable \n",
            "\n",
            "\n",
            "\n",
            "--- Page 1 ---\n",
            "vamseekrishna11@hotmail.com\n",
            "RSKN0VL9FW\n",
            "This file is meant for personal use by vamseekrishna11@hotmail.com only.\n",
            "Sharing or publishing the contents in part or full is liable for legal action.\n",
            "\n",
            "\n",
            "\n",
            "--- Page 2 ---\n",
            "Table of Contents\n",
            "1\n",
            "Front    ................................................................................................................................................................................................................\n",
            "1\n",
            "Cover    .......................................................................................................................................................................................................\n",
            "2\n",
            "Front Matter    .................................\n",
            "\n",
            "\n",
            "--- Page 3 ---\n",
            "491\n",
            "Chapter 44. Foot & Ankle Disorders    .....................................................................................................................................\n",
            "502\n",
            "Chapter 45. Tumors of Bones & Joints    ...............................................................................................................................\n",
            "510\n",
            "5 - Ear, Nose, Throat & Dental Disorders    ........................................................................................................\n",
            "\n",
            "\n",
            "--- Page 4 ---\n",
            "921\n",
            "Chapter 94. Adrenal Disorders    ................................................................................................................................................\n",
            "936\n",
            "Chapter 95. Polyglandular Deficiency Syndromes    ........................................................................................................\n",
            "939\n",
            "Chapter 96. Porphyrias    .................................................................................................................................\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-wNNalNxPKT"
      },
      "source": [
        "#### Checking the number of pages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the total number of pages by getting the length of the 'documents' list\n",
        "print(f\"Total number of pages: {len(documents)}\")"
      ],
      "metadata": {
        "id": "-NuC-6SNRT7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a72231-34be-4a52-aebd-07f7c448f7bf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of pages: 4114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LECMxTH-zB-R"
      },
      "source": [
        "### Data Chunking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Chunking\n",
        "\n",
        "# Initialize a RecursiveCharacterTextSplitter object using the tiktoken encoder 'cl100k_base',\n",
        "# with a maximum chunk size of 512 tokens and an overlap of 16 tokens between chunks.\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name='cl100k_base', # Specify the tiktoken encoding to use for token counting.\n",
        "    chunk_size=512,              # Set the maximum number of tokens per chunk.\n",
        "    chunk_overlap=16             # Set the number of tokens to overlap between consecutive chunks.\n",
        ")\n",
        "\n",
        "# Split the loaded documents into smaller chunks using the text splitter.\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "# Print the total number of chunks generated.\n",
        "print(f\"Number of chunks: {len(chunks)}\")\n",
        "\n",
        "# Print the content of the first chunk for a quick preview.\n",
        "print(f\"First chunk:\\n{chunks[0].page_content}\\n\")\n",
        "\n",
        "# Print out the first five chunks for inspection.\n",
        "for i, chunk in enumerate(chunks[:5]):\n",
        "    print(f\"--- Chunk {i+1} ---\")   # Print the current chunk number.\n",
        "    print(chunk)                    # Print the chunk object (which may include text and metadata).\n",
        "    print(\"\\n\")                     # Add a newline for readability between chunk outputs."
      ],
      "metadata": {
        "id": "ir9Zi8rKRUmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21ed91fa-8ba7-474f-bf1b-58181f1c1522"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 8473\n",
            "First chunk:\n",
            "vamseekrishna11@hotmail.com\n",
            "RSKN0VL9FW\n",
            "for personal use by vamseekrishna11@\n",
            "shing the contents in part or full is liable\n",
            "\n",
            "--- Chunk 1 ---\n",
            "page_content='vamseekrishna11@hotmail.com\\nRSKN0VL9FW\\nfor personal use by vamseekrishna11@\\nshing the contents in part or full is liable' metadata={'source': 'medical_diagnosis_manual.pdf', 'file_path': 'medical_diagnosis_manual.pdf', 'page': 0, 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Atop CHM to PDF Converter', 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creationDate': 'D:20120615054440Z', 'modDate': 'D:20250614133033Z', 'trapped': ''}\n",
            "\n",
            "\n",
            "--- Chunk 2 ---\n",
            "page_content='vamseekrishna11@hotmail.com\\nRSKN0VL9FW\\nThis file is meant for personal use by vamseekrishna11@hotmail.com only.\\nSharing or publishing the contents in part or full is liable for legal action.' metadata={'source': 'medical_diagnosis_manual.pdf', 'file_path': 'medical_diagnosis_manual.pdf', 'page': 1, 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Atop CHM to PDF Converter', 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creationDate': 'D:20120615054440Z', 'modDate': 'D:20250614133033Z', 'trapped': ''}\n",
            "\n",
            "\n",
            "--- Chunk 3 ---\n",
            "page_content='Table of Contents\\n1\\nFront    ................................................................................................................................................................................................................\\n1\\nCover    .......................................................................................................................................................................................................\\n2\\nFront Matter    ...........................................................................................................................................................................................\\n53\\n1 - Nutritional Disorders    ...............................................................................................................................................................\\n53\\nChapter 1. Nutrition: General Considerations    .....................................................................................................................\\n59\\nChapter 2. Undernutrition    .............................................................................................................................................................\\n69\\nChapter 3. Nutritional Support    ...................................................................................................................................................\\n76\\nChapter 4. Vitamin Deficiency, Dependency & Toxicity    ..................................................................................................\\n99\\nChapter 5. Mineral Deficiency & Toxicity    ..............................................................................................................................\\n108\\nChapter 6. Obesity & the Metabolic Syndrome    ...............................................................................................................\\n120\\n2 - Gastrointestinal Disorders    ..............................................................................................................................................\\n120\\nChapter 7. Approach to the Patient With Upper GI Complaints    ...............................................................................\\n132\\nChapter 8. Approach to the Patient With Lower GI Complaints    ...............................................................................\\n143\\nChapter 9. Diagnostic & Therapeutic GI Procedures    ....................................................................................................\\n150\\nChapter 10. GI Bleeding    ............................................................................................................................................................\\n158\\nChapter 11. Acute Abdomen & Surgical Gastroenterology    .........................................................................................\\n172\\nChapter 12. Esophageal & Swallowing Disorders    ..........................................................................................................\\n183\\nChapter 13. Gastritis & Peptic Ulcer Disease    ..................................................................................................................\\n196\\nChapter 14. Bezoars & Foreign Bodies    ..............................................................................................................................\\n199\\nChapter 15. Pancreatitis    ............................................................................................................................................................\\n206\\nChapter 16. Gastroenteritis    ......................................................................................................................................................\\n213\\nChapter 17. Malabsorption Syndromes    ..............................................................................................................................\\n225\\nChapter 18. Irritable Bowel Syndrome    ................................................................................................................................\\n229\\nChapter 19. Inflammatory Bowel Disease    .........................................................................................................................\\n241\\nChapter 20. Diverticular Disease    ...........................................................................................................................................\\n246\\nChapter 21. Anorectal Disorders    ............................................................................................................................................\\n254\\nChapter 22. Tumors of the GI Tract    ......................................................................................................................................\\n275\\n3 - Hepatic & Biliary Disorders    ............................................................................................................................................\\n275\\nChapter 23. Approach to the Patient With Liver Disease    ...........................................................................................\\n294\\nChapter 24. Testing for Hepatic & Biliary Disorders    ......................................................................................................\\n305' metadata={'source': 'medical_diagnosis_manual.pdf', 'file_path': 'medical_diagnosis_manual.pdf', 'page': 2, 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Atop CHM to PDF Converter', 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creationDate': 'D:20120615054440Z', 'modDate': 'D:20250614133033Z', 'trapped': ''}\n",
            "\n",
            "\n",
            "--- Chunk 4 ---\n",
            "page_content=\"305\\nChapter 25. Drugs & the Liver    ................................................................................................................................................\\n308\\nChapter 26. Alcoholic Liver Disease    ....................................................................................................................................\\n314\\nChapter 27. Fibrosis & Cirrhosis    ............................................................................................................................................\\n322\\nChapter 28. Hepatitis    ..................................................................................................................................................................\\n333\\nChapter 29. Vascular Disorders of the Liver    .....................................................................................................................\\n341\\nChapter 30. Liver Masses & Granulomas    ..........................................................................................................................\\n348\\nChapter 31. Gallbladder & Bile Duct Disorders    ...............................................................................................................\\n362\\n4 - Musculoskeletal & Connective Tissue Disorders    .........................................................................................\\n362\\nChapter 32. Approach to the Patient With Joint Disease    ............................................................................................\\n373\\nChapter 33. Autoimmune Rheumatic Disorders    ..............................................................................................................\\n391\\nChapter 34. Vasculitis    .................................................................................................................................................................\\n416\\nChapter 35. Joint Disorders    .....................................................................................................................................................\\n435\\nChapter 36. Crystal-Induced Arthritides    ..............................................................................................................................\\n443\\nChapter 37. Osteoporosis    .........................................................................................................................................................\\n448\\nChapter 38. Paget's Disease of Bone    ..................................................................................................................................\\n451\\nChapter 39. Osteonecrosis    .......................................................................................................................................................\\n455\\nChapter 40. Infections of Joints & Bones    ...........................................................................................................................\\n463\\nChapter 41. Bursa, Muscle & Tendon Disorders    .............................................................................................................\\n470\\nChapter 42. Neck & Back Pain    ...............................................................................................................................................\\n481\\nChapter 43. Hand Disorders    ....................................................................................................................................................\\nvamseekrishna11@hotmail.com\\nRSKN0VL9FW\\nThis file is meant for personal use by vamseekrishna11@hotmail.com only.\\nSharing or publishing the contents in part or full is liable for legal action.\" metadata={'source': 'medical_diagnosis_manual.pdf', 'file_path': 'medical_diagnosis_manual.pdf', 'page': 2, 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Atop CHM to PDF Converter', 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creationDate': 'D:20120615054440Z', 'modDate': 'D:20250614133033Z', 'trapped': ''}\n",
            "\n",
            "\n",
            "--- Chunk 5 ---\n",
            "page_content='491\\nChapter 44. Foot & Ankle Disorders    .....................................................................................................................................\\n502\\nChapter 45. Tumors of Bones & Joints    ...............................................................................................................................\\n510\\n5 - Ear, Nose, Throat & Dental Disorders    ..................................................................................................................\\n510\\nChapter 46. Approach to the Patient With Ear Problems    ...........................................................................................\\n523\\nChapter 47. Hearing Loss    .........................................................................................................................................................\\n535\\nChapter 48. Inner Ear Disorders    ............................................................................................................................................\\n542\\nChapter 49. Middle Ear & Tympanic Membrane Disorders    ........................................................................................\\n550\\nChapter 50. External Ear Disorders    .....................................................................................................................................\\n554\\nChapter 51. Approach to the Patient With Nasal & Pharyngeal Symptoms    .......................................................\\n567\\nChapter 52. Oral & Pharyngeal Disorders    .........................................................................................................................\\n578\\nChapter 53. Nose & Paranasal Sinus Disorders    .............................................................................................................\\n584\\nChapter 54. Laryngeal Disorders    ...........................................................................................................................................\\n590\\nChapter 55. Tumors of the Head & Neck    ...........................................................................................................................\\n600\\nChapter 56. Approach to Dental & Oral Symptoms    .......................................................................................................\\n619\\nChapter 57. Common Dental Disorders    .............................................................................................................................\\n629\\nChapter 58. Dental Emergencies    ..........................................................................................................................................\\n635\\nChapter 59. Temporomandibular Disorders    ......................................................................................................................\\n641\\n6 - Eye Disorders    ............................................................................................................................................................................\\n641\\nChapter 60. Approach to the Ophthalmologic Patient    ..................................................................................................\\n669\\nChapter 61. Refractive Error    ...................................................................................................................................................\\n674\\nChapter 62. Eyelid & Lacrimal Disorders    ...........................................................................................................................\\n680\\nChapter 63. Conjunctival & Scleral Disorders    .................................................................................................................\\n690\\nChapter 64. Corneal Disorders    ...............................................................................................................................................\\n703\\nChapter 65. Glaucoma    ...............................................................................................................................................................\\n710\\nChapter 66. Cataract    ...................................................................................................................................................................\\n713\\nChapter 67. Uveitis    ......................................................................................................................................................................\\n719\\nChapter 68. Retinal Disorders    .................................................................................................................................................\\n731\\nChapter 69. Optic Nerve Disorders    ......................................................................................................................................\\n737\\nChapter 70. Orbital Diseases    ..................................................................................................................................................\\n742\\n7 - Dermatologic Disorders    ....................................................................................................................................................\\n742' metadata={'source': 'medical_diagnosis_manual.pdf', 'file_path': 'medical_diagnosis_manual.pdf', 'page': 3, 'total_pages': 4114, 'format': 'PDF 1.7', 'title': 'The Merck Manual of Diagnosis & Therapy, 19th Edition', 'author': '', 'subject': '', 'keywords': '', 'creator': 'Atop CHM to PDF Converter', 'producer': 'pdf-lib (https://github.com/Hopding/pdf-lib)', 'creationDate': 'D:20120615054440Z', 'modDate': 'D:20250614133033Z', 'trapped': ''}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvHVejcWz0Bl"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choosing Embedded model:\n",
        "\n",
        "\"all-MiniLM-L6-v2\" is one of the best all-round sentence embedding models for performance, speed, and memory.\n",
        "For larger projects and highest accuracy, you might consider \"all-mpnet-base-v2\", but \"all-MiniLM-L6-v2\" is often preferred for its speed and low resource use.\n",
        "You can swap \"all-MiniLM-L6-v2\" for another model as needed."
      ],
      "metadata": {
        "id": "oUO2eRv9Tr2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a strong, widely used all-purpose model\n",
        "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "R3CAgoUeRVLa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438,
          "referenced_widgets": [
            "706e1b3deeb1467885716be6fa97aab4",
            "3250a04d1a0f4e1b985f2b4d0c23b4b9",
            "881de19a806e4100badc3963b9681b09",
            "cb3ba3c3792e44faaeeab60dc25d94f2",
            "3f051b77487c4c76978e8acb1e606a2d",
            "420cfdef2877473e8d6f6474803aa785",
            "f570099ac9864a66bac3f11fb24fa0e0",
            "d5f78621fbb64d07b9d7b79378d3fb74",
            "00e8bdfe9f6e4090b30ac681f397b021",
            "08b50c0d394a4f20862bb6d5497b80d6",
            "571a15101bf14850b107fb753b1d5a11",
            "6a2bb891ed954a69883a5987f85e4929",
            "8ca826b2baef47758e397db7fbecf5b2",
            "125d23499c1a4619a47f89e006eb91a8",
            "ec706f8b5da84e169e683177f3f57353",
            "d4bb34e229854077881356ef2819a40a",
            "cde8bb4923d3486a80f7e5450c655b7a",
            "ae8dd9c5ac65483ea95b4737d3a171d9",
            "d6340a4c60dc4cc386663c08c9c17eb0",
            "e6b763b034674c07b59e69a8be3d324f",
            "b16231c545aa41d88109832ae9fed771",
            "5d39ba11ccd14ae194841f90740fc571",
            "5069b3b395d640b2b38f032fd36b2d0a",
            "15d2394233454074a3cdb29e4d9136f1",
            "efa5b5b4d7254e029505151740f0632a",
            "b65768d0019f4369a1f0a9c938a1353a",
            "74da3e694a8b405386545ae30d555155",
            "ac1db45b508046278e5a587bd7745ec1",
            "35f63ef372b246c3b3df56e4d17c11c8",
            "ef95062ad5134531a6ef6b5acdeb3b66",
            "584a3e9ccad748448856f7229afef4fb",
            "716b5676003d482fb25f957f5d4afdd3",
            "cfe2b83f7e084ee5a23089f832968a73",
            "b681e6d2c9fa4307bb4ea9eed6cfcd1d",
            "85b2a5e765e24d8caf83e58c6e32eea5",
            "d941f6b2aaf94ae281293cfad9694eef",
            "d03b8f8fce9547f8a90d3c273b06b8c4",
            "53dac2b2351a423a94846e602cc23abf",
            "ae32db4537e54e1b99c003d643b94095",
            "f86c3dedd9254b22986b9f64741d8346",
            "e08e5d4611184c1aab9abc1bff84df1b",
            "8fd821786c124a37ab5ebc2723fd659b",
            "94c8b1a4d419485e9f32d9154f6e1a45",
            "dc69b743ac6340aab3c4c187a3f3455d",
            "f662aa8777404e22922a2eb02db2e898",
            "a4816f04b8e24efb9baa83951840dbef",
            "1435f28568384c8bb10dc6a0ab26b0c8",
            "38e95616e3f64248808835e642f44fab",
            "b21189da329346e7a8a5c93f50145c94",
            "320c7cffccf8444d803c07f4a2dfa75f",
            "ed7ffefb9f23493cb4636b820c949d80",
            "53d02ab2582c4379ab7ad24c53599e48",
            "454c76f4101d41e68fded64d8439820b",
            "9c53f80c20a144b0a6a7be70cf1ef6ec",
            "de3f2647d7514808913495e2e6480168",
            "f73e34d3fd8f4a8198b840e2eee23cec",
            "b781c1b7e51d43678c3d922a37bdc2e3",
            "a9023784b86448259d154c374db9fb4c",
            "03b40c5dbb084e28944986c8fa309a3d",
            "867840b4c11b41f1aae4827b39125119",
            "4f7c76cee4224100b4e05765c75ea1a3",
            "50c2359884244e4f99ce60b8d8074876",
            "0d1e47d682b54368b9752d13d6418b4e",
            "5558b514a9d1418bbb4934920d88eadf",
            "9213cb8ec374425281218bf18f2fff0d",
            "2e0cb588b2be4e3da9be61eb2901424b",
            "962b5c561fb440a0943689b3e6ef13a5",
            "076736027f444604be29586a577a6120",
            "d22fbc337fa840da9502254afbff9aec",
            "11465f15acdf43338d84b848cf2bf808",
            "45d9acbab3f54ba896017b1686f62c50",
            "82e90094f76640a1b1242d883859eaa0",
            "0fdaddab10064d19a4842a2bddf9b301",
            "1a4b9575b83e4e3bb97e42c3ccace552",
            "7f0c8521846d4529bd0d4a755d316932",
            "d43ebb0a586f4a32aed59d9c7206b4a5",
            "e2ea24dae9744f49a30eea86255b8c97",
            "34429d5b7ce44215ab4af95264e16ddd",
            "4ced3875fa5d49e3b4845fd08effc449",
            "a544939432af4b299e8fee7ad0bb7f15",
            "1559a9ba00e449de9d85c715b95ccb13",
            "6c395a23ba7a43f69a4bf0b9c10a75b0",
            "e8b91f10bcc94d919825981283fe64d2",
            "bb87d30e804a4caca059c6965fed971f",
            "0eaf6b194ded4605860c63bc49b1a2c1",
            "5e93d837e216485ab31bc6f3985f9f67",
            "ab864b0063e441359350b1506c57fc16",
            "df257ec1cf584b41a8cca7d5ef9a6ae0",
            "d6b381b145a24e1aad92150c0afdf582",
            "e56a196fa9884174ae1356ea01d479bf",
            "acb5beaf03ea4143a8e9ef61ac2f036d",
            "baab6c5156d542bfaf59e2892b90601c",
            "434dd012e3904cd4ac9125f125913abf",
            "d15aa8ffffcb4aa881cf4f0233ae17ff",
            "9e10a4f85a7d4e80aaabef080333cc70",
            "82b11638a17d451cb8c481e19c3c6adb",
            "001559959df6443888eb95655c519269",
            "818fce7158154c9dbb4128b181ce6982",
            "618dc3d70c064e42bd9b8d98507610c1",
            "8e76928486744af4848469cf228ecbae",
            "73115b1d94e04bea825310017d06693d",
            "6954e6c0da304ea98070b51ff11202ba",
            "c39c6db80e8e439a97d208dab56bda60",
            "52b088556281470fabf944394e18de0c",
            "a43b45e2f3ab4695aaa8e648f68f1e4f",
            "f74a46dbf1964a10b17b350b5b8c1ff0",
            "a588ae6a6f024e2a8b7cc46005437169",
            "70f01b7e7a42445e8eb0f24bd93e7f7f",
            "c87768cc3f094ea598f05dc0a2454a4a",
            "1cb3ab1177fc4eec9d9fb7ec7486d43d",
            "5b9ca81a015b4a9f922ded00fc4651ce",
            "78433e56951e48378045388063e279b1",
            "b3effa245c5a495f83edc3b60b8d45c7",
            "a46d2c8116a140c3926cb1d31936581f",
            "d0880598813641779adfe399bd480036",
            "1c0bbf8e555f4bd3a98e2b4849e4f6c5",
            "48af9a0b396f4d189e04b6193c90015a",
            "ea6081926f85401ea0e20a27c42b8b33",
            "422b8ff121f24d6e8e82a0102a36db0c",
            "237391bb84574d3881729bbcd7bc1da3",
            "faf26c569407495cb453e9b25cb30538",
            "ee6d5d843fec4f609af1798810308f51",
            "aae7e5c659774c569b49addffe90d0f2",
            "bc5ba2e0cd474de4931bd6a8fb1802d6",
            "2c9b7345adc547e39860d924c5181cc1",
            "3ce53dc13a0b49fdac37e40e82cab95f",
            "67739c7901dc4be8b9b3f79dab044121",
            "cbcf678538e24456bc9396be20c83349",
            "ad1755caebac499d9533ceb74d3a4f6f",
            "d0f69ad164cb47d6b4b5fd808ce4985c",
            "4ffb1f1a19944511b778aef6081604cc",
            "ad4c3bd868394c309390e0906ade4e20"
          ]
        },
        "outputId": "cb9d05c6-6108-4e9d-f1c9-1ac72ca9a422"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "706e1b3deeb1467885716be6fa97aab4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a2bb891ed954a69883a5987f85e4929"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5069b3b395d640b2b38f032fd36b2d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b681e6d2c9fa4307bb4ea9eed6cfcd1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f662aa8777404e22922a2eb02db2e898"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f73e34d3fd8f4a8198b840e2eee23cec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "962b5c561fb440a0943689b3e6ef13a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34429d5b7ce44215ab4af95264e16ddd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6b381b145a24e1aad92150c0afdf582"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e76928486744af4848469cf228ecbae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b9ca81a015b4a9f922ded00fc4651ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee6d5d843fec4f609af1798810308f51"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiKCOv4X0d7B"
      },
      "source": [
        "### Creating a Vector Database and the Retriever"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add the data into vector DB\n",
        "\n",
        "# Create the Chroma vector database from your document chunks using the embedding model\n",
        "vector_db = Chroma.from_documents(chunks, embedding_model)\n",
        "\n",
        "# Create a retriever from the Chroma vector database with appropriate search method and k value\n",
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"similarity\",   # Use similarity search for most retrieval tasks\n",
        "    search_kwargs={\"k\": 5}      # Return the top 5 most similar documents\n",
        ")\n",
        "\n",
        "# Now, `retriever` can be used to retrieve relevant documents based on a query\n",
        "\n",
        "# Example of using the retriever (replace with your actual query)\n",
        "# query = \"What is appendicitis?\"\n",
        "# relevant_docs = retriever.get_relevant_documents(query)\n",
        "# print(relevant_docs)\n",
        "\n",
        "print(\"Vector database created and populated with document chunks.\")\n",
        "print(\"Retriever created.\")\n"
      ],
      "metadata": {
        "id": "vHHt1MQQRVzs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2995c687-a8f9-4e8c-d122-e71282a92be8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
            "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector database created and populated with document chunks.\n",
            "Retriever created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEa5sKc41T1z"
      },
      "source": [
        "### Retriever Testing for 5 similar responses for the given query"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example query to test the retriever\n",
        "query = \"What are the common symptoms and treatments for pulmonary embolism?\"\n",
        "\n",
        "# Use the retriever to get relevant documents for the query\n",
        "relevant_docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "# Print the retrieved documents\n",
        "print(\"Relevant documents retrieved by the retriever:\")\n",
        "\n",
        "# Print the number of relevant documents retrieved\n",
        "print(\"Length of relevant documents: \")\n",
        "print(len(relevant_docs))\n",
        "\n",
        "# Loop through the retrieved documents and print their content\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"--- Document {i+1} ---\")      # Print the document number\n",
        "    print(doc.page_content)               # Print the content of the document\n",
        "    print(\"\\n\")                           # Print a newline for readability between documents"
      ],
      "metadata": {
        "id": "wBlQUGx3RWUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a86af550-f096-48dd-a336-6d3a58b71dc9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevant documents retrieved by the retriever:\n",
            "Length of relevant documents: \n",
            "5\n",
            "--- Document 1 ---\n",
            "Chapter 194. Pulmonary Embolism\n",
            "Introduction\n",
            "Pulmonary embolism (PE) is the occlusion of ≥ 1 pulmonary arteries by thrombi that originate\n",
            "elsewhere, typically in the large veins of the lower extremities or pelvis. Risk factors are\n",
            "conditions that impair venous return, conditions that cause endothelial injury or dysfunction,\n",
            "and underlying hypercoagulable states. Symptoms are nonspecific and include dyspnea,\n",
            "pleuritic chest pain, cough, and, in severe cases, syncope or cardiorespiratory arrest. Signs are\n",
            "also nonspecific and may include tachypnea, tachycardia, hypotension, and a loud pulmonic\n",
            "component of the 2nd heart sound. Diagnosis is based on a CT angiogram, ventilation/perfusion\n",
            "scan, or a pulmonary arteriogram. Treatment is with anticoagulants and, sometimes, clot\n",
            "dissolution with thrombolytics or surgical removal. Preventive measures include anticoagulants\n",
            "and sometimes insertion of an inferior vena caval filter.\n",
            "PE affects an estimated 117 people per 100,000 person years, resulting in about 350,000 cases yearly,\n",
            "and causes up to 85,000 deaths/yr. PE affects mainly adults.\n",
            "Etiology\n",
            "Nearly all PEs arise from thrombi in the lower extremity or pelvic veins (deep venous thrombosis [DVT]\n",
            "—see p. 2224). Thrombi in either the lower extremity or pelvic veins may be occult. Risk of embolization is\n",
            "higher with thrombi proximal to the calf veins. Thromboemboli can also originate in upper extremity veins\n",
            "(associated with central venous catheters) or from right-sided cardiac chambers. Risk factors for DVT and\n",
            "PE are similar in children and adults and include conditions that impair venous return, conditions that\n",
            "cause endothelial injury or dysfunction, and underlying hypercoagulability disorders (see\n",
            "Table 194-1). Bed rest and confinement without walking, even for a few hours, are common precipitators.\n",
            "Pathophysiology\n",
            "Once DVT develops, clots may dislodge and travel through the venous system and right side of the heart\n",
            "to lodge in the pulmonary arteries, where they partially or completely occlude one or more vessels. The\n",
            "\n",
            "\n",
            "--- Document 2 ---\n",
            "Chapter 194. Pulmonary Embolism\n",
            "Introduction\n",
            "Pulmonary embolism (PE) is the occlusion of ≥ 1 pulmonary arteries by thrombi that originate\n",
            "elsewhere, typically in the large veins of the lower extremities or pelvis. Risk factors are\n",
            "conditions that impair venous return, conditions that cause endothelial injury or dysfunction,\n",
            "and underlying hypercoagulable states. Symptoms are nonspecific and include dyspnea,\n",
            "pleuritic chest pain, cough, and, in severe cases, syncope or cardiorespiratory arrest. Signs are\n",
            "also nonspecific and may include tachypnea, tachycardia, hypotension, and a loud pulmonic\n",
            "component of the 2nd heart sound. Diagnosis is based on a CT angiogram, ventilation/perfusion\n",
            "scan, or a pulmonary arteriogram. Treatment is with anticoagulants and, sometimes, clot\n",
            "dissolution with thrombolytics or surgical removal. Preventive measures include anticoagulants\n",
            "and sometimes insertion of an inferior vena caval filter.\n",
            "PE affects an estimated 117 people per 100,000 person years, resulting in about 350,000 cases yearly,\n",
            "and causes up to 85,000 deaths/yr. PE affects mainly adults.\n",
            "Etiology\n",
            "Nearly all PEs arise from thrombi in the lower extremity or pelvic veins (deep venous thrombosis [DVT]\n",
            "—see p. 2224). Thrombi in either the lower extremity or pelvic veins may be occult. Risk of embolization is\n",
            "higher with thrombi proximal to the calf veins. Thromboemboli can also originate in upper extremity veins\n",
            "(associated with central venous catheters) or from right-sided cardiac chambers. Risk factors for DVT and\n",
            "PE are similar in children and adults and include conditions that impair venous return, conditions that\n",
            "cause endothelial injury or dysfunction, and underlying hypercoagulability disorders (see\n",
            "Table 194-1). Bed rest and confinement without walking, even for a few hours, are common precipitators.\n",
            "Pathophysiology\n",
            "Once DVT develops, clots may dislodge and travel through the venous system and right side of the heart\n",
            "to lodge in the pulmonary arteries, where they partially or completely occlude one or more vessels. The\n",
            "\n",
            "\n",
            "--- Document 3 ---\n",
            "right-sided infective endocarditis, and septic thrombophlebitis. Septic embolism causes symptoms and\n",
            "signs of pneumonia or sepsis. Initially, nodular opacities appear on the chest x-ray; the appearance may\n",
            "progress to peripheral infiltrates, and emboli may cavitate (particularly emboli caused by Staphylococcus\n",
            "aureus). Treatment includes that of the underlying infection.\n",
            "Foreign body embolism caused by introduction of particulate matter into the pulmonary arterial system,\n",
            "usually by IV injection of inorganic substances, such as talc by heroin users or elemental mercury by\n",
            "patients with mental disorders. Focal pulmonary infiltrates may result.\n",
            "Tumor embolism is a rare complication of cancer (usually adenocarcinoma) in which neoplastic cells\n",
            "from an organ enter the systemic venous and pulmonary arterial system, where they lodge, proliferate,\n",
            "and obstruct flow. Patients typically present with dyspnea and pleuritic chest pain and signs of cor\n",
            "pulmonale that develop over weeks to months. Diagnosis, which is suggested by micronodules or diffuse\n",
            "pulmonary infiltrates on chest x-ray, can be confirmed by biopsy or occasionally by cytologic aspiration\n",
            "and histologic study of pulmonary capillary blood.\n",
            "ECG most often shows tachycardia and various ST-T wave abnormalities, which are not specific for PE\n",
            "(see\n",
            "Fig. 194-1). An S1Q3T3 or a new right bundle branch block may indicate the effect of abrupt rise in right\n",
            "ventricular pressure on right ventricular conduction; these findings are moderately specific but insensitive,\n",
            "occurring in only about 5% of patients. Right axis deviation (R > S in V1) and P-pulmonale may be\n",
            "present. T-wave inversion in leads V1 to V4 also occurs.\n",
            "Clinical probability: Clinical probability of PE can be assessed by combining ECG and chest x-ray\n",
            "findings with findings from the history and physical examination (see\n",
            "Table 194-2). Judgment of whether PE is more likely than an alternate diagnosis is somewhat subjective.\n",
            "PE should probably be considered more likely if ≥ 1 of its symptoms and signs, particularly dyspnea,\n",
            "The Merck Manual of Diagnosis & Therapy, 19th Edition\n",
            "Chapter 194. Pulmonary Embolism\n",
            "2072\n",
            "vamseekrishna11@hotmail.com\n",
            "\n",
            "\n",
            "--- Document 4 ---\n",
            "right-sided infective endocarditis, and septic thrombophlebitis. Septic embolism causes symptoms and\n",
            "signs of pneumonia or sepsis. Initially, nodular opacities appear on the chest x-ray; the appearance may\n",
            "progress to peripheral infiltrates, and emboli may cavitate (particularly emboli caused by Staphylococcus\n",
            "aureus). Treatment includes that of the underlying infection.\n",
            "Foreign body embolism caused by introduction of particulate matter into the pulmonary arterial system,\n",
            "usually by IV injection of inorganic substances, such as talc by heroin users or elemental mercury by\n",
            "patients with mental disorders. Focal pulmonary infiltrates may result.\n",
            "Tumor embolism is a rare complication of cancer (usually adenocarcinoma) in which neoplastic cells\n",
            "from an organ enter the systemic venous and pulmonary arterial system, where they lodge, proliferate,\n",
            "and obstruct flow. Patients typically present with dyspnea and pleuritic chest pain and signs of cor\n",
            "pulmonale that develop over weeks to months. Diagnosis, which is suggested by micronodules or diffuse\n",
            "pulmonary infiltrates on chest x-ray, can be confirmed by biopsy or occasionally by cytologic aspiration\n",
            "and histologic study of pulmonary capillary blood.\n",
            "ECG most often shows tachycardia and various ST-T wave abnormalities, which are not specific for PE\n",
            "(see\n",
            "Fig. 194-1). An S1Q3T3 or a new right bundle branch block may indicate the effect of abrupt rise in right\n",
            "ventricular pressure on right ventricular conduction; these findings are moderately specific but insensitive,\n",
            "occurring in only about 5% of patients. Right axis deviation (R > S in V1) and P-pulmonale may be\n",
            "present. T-wave inversion in leads V1 to V4 also occurs.\n",
            "Clinical probability: Clinical probability of PE can be assessed by combining ECG and chest x-ray\n",
            "findings with findings from the history and physical examination (see\n",
            "Table 194-2). Judgment of whether PE is more likely than an alternate diagnosis is somewhat subjective.\n",
            "PE should probably be considered more likely if ≥ 1 of its symptoms and signs, particularly dyspnea,\n",
            "The Merck Manual of Diagnosis & Therapy, 19th Edition\n",
            "Chapter 194. Pulmonary Embolism\n",
            "2072\n",
            "vamseekrishna11@hotmail.com\n",
            "\n",
            "\n",
            "--- Document 5 ---\n",
            "consequences depend on the size and number of emboli, the pulmonary reaction, the underlying\n",
            "condition of the lungs, and the ability of the body's intrinsic thrombolytic system to dissolve the clots.\n",
            "[Table 194-1. Risk Factors for Deep Venous Thrombosis and Pulmonary Embolism]\n",
            "Small emboli may have no acute physiologic effects; many begin to lyse immediately and resolve within\n",
            "hours or days. Larger emboli can cause a reflex increase in ventilation (tachypnea), hypoxemia due to\n",
            "ventilation/perfusion (V/Q) mismatch, shunting and low mixed venous O2 content as a result of low\n",
            "cardiac output, atelectasis due to alveolar hypocapnia and abnormalities in surfactant, and an increase in\n",
            "pulmonary vascular resistance caused by mechanical obstruction and vasoconstriction. Endogenous lysis\n",
            "reduces most emboli, even those of moderate size, without treatment, and physiologic alterations\n",
            "decrease over hours or days. Some emboli resist lysis and may organize and persist. Occasionally,\n",
            "chronic residual obstruction leads to pulmonary hypertension (chronic thromboembolic pulmonary\n",
            "hypertension) that may develop over years and result in chronic right heart failure. When large emboli\n",
            "occlude major arteries, or when many small emboli occlude > 50% of the distal arterial system, right\n",
            "ventricular pressure increases, causing acute right ventricular failure, failure with shock (massive PE), or\n",
            "sudden death in severe cases. Risk factors for death include age > 70 yr, cancer, and COPD. The risk of\n",
            "death depends on the degree and rate of rise of right-sided pressures and on the patient's underlying\n",
            "cardiopulmonary status; higher pressures more commonly occur among patients with preexisting\n",
            "cardiopulmonary disease. Otherwise healthy patients may survive a PE that occludes > 50% of the\n",
            "pulmonary vascular bed.\n",
            "Pulmonary infarction occurs in < 10% of patients diagnosed with PE. This low rate has been attributed to\n",
            "the dual blood supply to the lung (ie, bronchial and pulmonary).\n",
            "The Merck Manual of Diagnosis & Therapy, 19th Edition\n",
            "Chapter 194. Pulmonary Embolism\n",
            "2070\n",
            "vamseekrishna11@hotmail.com\n",
            "RSKN0VL9FW\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading of LLM for RAG"
      ],
      "metadata": {
        "id": "NEDKUqJ0YP0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the **generation part** of **Retrieval-Augmented Generation (RAG)**, an **LLM (Large Language Model)** is needed because it effectively understands complex queries and generates **coherent, context-aware responses** in natural language. It seamlessly **integrates and synthesizes** the retrieved context with the user's query, ensuring accurate and relevant answers. LLMs handle **ambiguous or complex questions** by reasoning over the retrieved knowledge, generating **fluent and human-like text** for a better user experience.\n"
      ],
      "metadata": {
        "id": "nPVO5aCPYW56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and loading the LLM"
      ],
      "metadata": {
        "id": "YAcoTYmNYaQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download   # Import the function to download models and files from the Hugging Face Hub\n",
        "\n",
        "from llama_cpp import Llama                   # Import the Llama class for running Llama models locally.\n",
        "                                              # Note: This import may throw an error if you have installed the GPU version of llama_cpp\n",
        "                                              # but have not properly enabled or configured your GPU."
      ],
      "metadata": {
        "id": "kFqpIusVYh85"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"         # Specify the Hugging Face repository or local path for the Llama-2-13B-chat model in GGUF format\n",
        "model_basename = \"llama-2-13b-chat.Q5_K_M.gguf\"               # Specify the filename of the quantized model to use (Q5_K_M quantization, GGUF format)"
      ],
      "metadata": {
        "id": "w4z0HG-mY84a"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = hf_hub_download(                      # Call the hf_hub_download function to download a file from the Hugging Face Hub.\n",
        "    repo_id=model_name_or_path,                    # Specify the repository ID or path (e.g., \"TheBloke/Llama-2-13B-chat-GGUF\") where the model is hosted.\n",
        "    filename=model_basename                        # Specify the exact filename of the model weights to download (e.g., \"llama-2-13b-chat.Q5_K_M.gguf\").\n",
        ")                                                  # The function returns the local file path to the downloaded model file and assigns it to model_path."
      ],
      "metadata": {
        "id": "GuolEarUZG2H"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw8qcwq66B0C",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### System and User Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GF_4399TRW5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkIteX4m6mny"
      },
      "source": [
        "### Response Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_rag_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=k)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "\n",
        "    # Combine document chunks into a single context\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    user_message = qna_user_message_template.replace('{context}', context_for_query)\n",
        "    user_message = user_message.replace('{question}', user_input)\n",
        "\n",
        "    prompt = qna_system_message + '\\n' + user_message\n",
        "\n",
        "    # Generate the response\n",
        "    try:\n",
        "        response = llm(\n",
        "                  prompt=prompt,\n",
        "                  max_tokens=max_tokens,\n",
        "                  temperature=temperature,\n",
        "                  top_p=top_p,\n",
        "                  top_k=top_k\n",
        "                  )\n",
        "\n",
        "        # Extract and print the model's response\n",
        "        response = response['choices'][0]['text'].strip()\n",
        "    except Exception as e:\n",
        "        response = f'Sorry, I encountered the following error: \\n {e}'\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "5jFvGnOJRXZx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Answering using RAG"
      ],
      "metadata": {
        "id": "ffP1SRYbPQHN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjajBEj06B0E"
      },
      "source": [
        "### Query 1: What is the protocol for managing sepsis in a critical care unit?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nlo9sMpPRbTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDw8zXuq6B0F"
      },
      "source": [
        "### Query 2: What are the common symptoms for appendicitis, and can it be cured via medicine? If not, what surgical procedure should be followed to treat it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PVReF4G8RbzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TggYyQPL6B0G"
      },
      "source": [
        "### Query 3: What are the effective treatments or solutions for addressing sudden patchy hair loss, commonly seen as localized bald spots on the scalp, and what could be the possible causes behind it?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0aRbadGtRcX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TgxdI-_6B0G"
      },
      "source": [
        "### Query 4:  What treatments are recommended for a person who has sustained a physical injury to brain tissue, resulting in temporary or permanent impairment of brain function?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0vzRX1TcRc29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlHXYCkm6B0H"
      },
      "source": [
        "### Query 5: What are the necessary precautions and treatment steps for a person who has fractured their leg during a hiking trip, and what should be considered for their care and recovery?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sarpUibcRdhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning"
      ],
      "metadata": {
        "id": "K7TYrqycEITB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UYBR-hcReSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyQrTipNfuBN"
      },
      "source": [
        "## Output Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groundedness_rater_system_message  = \"\""
      ],
      "metadata": {
        "id": "IHbfLAxAGdhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevance_rater_system_message = \"\""
      ],
      "metadata": {
        "id": "159OZZa0Rinv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message_template = \"\""
      ],
      "metadata": {
        "id": "RLqiSn-iRwSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_ground_relevance_response(user_input,k=3,max_tokens=128,temperature=0,top_p=0.95,top_k=50):\n",
        "    global qna_system_message,qna_user_message_template\n",
        "    # Retrieve relevant document chunks\n",
        "    relevant_document_chunks = retriever.get_relevant_documents(query=user_input,k=3)\n",
        "    context_list = [d.page_content for d in relevant_document_chunks]\n",
        "    context_for_query = \". \".join(context_list)\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    prompt = f\"\"\"[INST]{qna_system_message}\\n\n",
        "                {'user'}: {qna_user_message_template.format(context=context_for_query, question=user_input)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response = llm(\n",
        "            prompt=prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    answer =  response[\"choices\"][0][\"text\"]\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    groundedness_prompt = f\"\"\"[INST]{groundedness_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    # Combine user_prompt and system_message to create the prompt\n",
        "    relevance_prompt = f\"\"\"[INST]{relevance_rater_system_message}\\n\n",
        "                {'user'}: {user_message_template.format(context=context_for_query, question=user_input, answer=answer)}\n",
        "                [/INST]\"\"\"\n",
        "\n",
        "    response_1 = llm(\n",
        "            prompt=groundedness_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    response_2 = llm(\n",
        "            prompt=relevance_prompt,\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            top_k=top_k,\n",
        "            stop=['INST'],\n",
        "            )\n",
        "\n",
        "    return response_1['choices'][0]['text'],response_2['choices'][0]['text']"
      ],
      "metadata": {
        "id": "XIbZybyuRi2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7QICRU-njdj"
      },
      "source": [
        "## Actionable Insights and Business Recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybRlzaIhWaM9"
      },
      "source": [
        "<font size=6 color='blue'>Power Ahead</font>\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QDw8zXuq6B0F",
        "TggYyQPL6B0G",
        "1TgxdI-_6B0G",
        "FlHXYCkm6B0H",
        "K7TYrqycEITB",
        "yyQrTipNfuBN",
        "Y7QICRU-njdj"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3802fcd9847a4a94bf34e14ee569deb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ad5597d8cf14b9795d6d3032c949870",
              "IPY_MODEL_0753920b3480480c99924ed365218595",
              "IPY_MODEL_692b5837aaa04c1580dd4408de709e37"
            ],
            "layout": "IPY_MODEL_a809e72e05124e3b8b03bc0f33914e40"
          }
        },
        "1ad5597d8cf14b9795d6d3032c949870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bcaef1aaace405db7c572d4e673753b",
            "placeholder": "​",
            "style": "IPY_MODEL_e2927971513240c29b1118b95550994e",
            "value": "llama-2-7b-chat.Q4_K_M.gguf: 100%"
          }
        },
        "0753920b3480480c99924ed365218595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad8676e6089d433bac36b44924b755f4",
            "max": 4081004224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e86d91d945f4d308a7db0bdf4be5dcc",
            "value": 4081004224
          }
        },
        "692b5837aaa04c1580dd4408de709e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444a920abaa341e9a972df8880e2338c",
            "placeholder": "​",
            "style": "IPY_MODEL_7cf5f74dd9c04a7b8637a96710b07a68",
            "value": " 4.08G/4.08G [00:17&lt;00:00, 236MB/s]"
          }
        },
        "a809e72e05124e3b8b03bc0f33914e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bcaef1aaace405db7c572d4e673753b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2927971513240c29b1118b95550994e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad8676e6089d433bac36b44924b755f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e86d91d945f4d308a7db0bdf4be5dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "444a920abaa341e9a972df8880e2338c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf5f74dd9c04a7b8637a96710b07a68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "706e1b3deeb1467885716be6fa97aab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3250a04d1a0f4e1b985f2b4d0c23b4b9",
              "IPY_MODEL_881de19a806e4100badc3963b9681b09",
              "IPY_MODEL_cb3ba3c3792e44faaeeab60dc25d94f2"
            ],
            "layout": "IPY_MODEL_3f051b77487c4c76978e8acb1e606a2d"
          }
        },
        "3250a04d1a0f4e1b985f2b4d0c23b4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_420cfdef2877473e8d6f6474803aa785",
            "placeholder": "​",
            "style": "IPY_MODEL_f570099ac9864a66bac3f11fb24fa0e0",
            "value": ""
          }
        },
        "881de19a806e4100badc3963b9681b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f78621fbb64d07b9d7b79378d3fb74",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00e8bdfe9f6e4090b30ac681f397b021",
            "value": 0
          }
        },
        "cb3ba3c3792e44faaeeab60dc25d94f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08b50c0d394a4f20862bb6d5497b80d6",
            "placeholder": "​",
            "style": "IPY_MODEL_571a15101bf14850b107fb753b1d5a11",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "3f051b77487c4c76978e8acb1e606a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420cfdef2877473e8d6f6474803aa785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f570099ac9864a66bac3f11fb24fa0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5f78621fbb64d07b9d7b79378d3fb74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "00e8bdfe9f6e4090b30ac681f397b021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08b50c0d394a4f20862bb6d5497b80d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571a15101bf14850b107fb753b1d5a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a2bb891ed954a69883a5987f85e4929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ca826b2baef47758e397db7fbecf5b2",
              "IPY_MODEL_125d23499c1a4619a47f89e006eb91a8",
              "IPY_MODEL_ec706f8b5da84e169e683177f3f57353"
            ],
            "layout": "IPY_MODEL_d4bb34e229854077881356ef2819a40a"
          }
        },
        "8ca826b2baef47758e397db7fbecf5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cde8bb4923d3486a80f7e5450c655b7a",
            "placeholder": "​",
            "style": "IPY_MODEL_ae8dd9c5ac65483ea95b4737d3a171d9",
            "value": "modules.json: 100%"
          }
        },
        "125d23499c1a4619a47f89e006eb91a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6340a4c60dc4cc386663c08c9c17eb0",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6b763b034674c07b59e69a8be3d324f",
            "value": 349
          }
        },
        "ec706f8b5da84e169e683177f3f57353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b16231c545aa41d88109832ae9fed771",
            "placeholder": "​",
            "style": "IPY_MODEL_5d39ba11ccd14ae194841f90740fc571",
            "value": " 349/349 [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "d4bb34e229854077881356ef2819a40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde8bb4923d3486a80f7e5450c655b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae8dd9c5ac65483ea95b4737d3a171d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6340a4c60dc4cc386663c08c9c17eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b763b034674c07b59e69a8be3d324f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b16231c545aa41d88109832ae9fed771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d39ba11ccd14ae194841f90740fc571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5069b3b395d640b2b38f032fd36b2d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15d2394233454074a3cdb29e4d9136f1",
              "IPY_MODEL_efa5b5b4d7254e029505151740f0632a",
              "IPY_MODEL_b65768d0019f4369a1f0a9c938a1353a"
            ],
            "layout": "IPY_MODEL_74da3e694a8b405386545ae30d555155"
          }
        },
        "15d2394233454074a3cdb29e4d9136f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac1db45b508046278e5a587bd7745ec1",
            "placeholder": "​",
            "style": "IPY_MODEL_35f63ef372b246c3b3df56e4d17c11c8",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "efa5b5b4d7254e029505151740f0632a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef95062ad5134531a6ef6b5acdeb3b66",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_584a3e9ccad748448856f7229afef4fb",
            "value": 116
          }
        },
        "b65768d0019f4369a1f0a9c938a1353a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_716b5676003d482fb25f957f5d4afdd3",
            "placeholder": "​",
            "style": "IPY_MODEL_cfe2b83f7e084ee5a23089f832968a73",
            "value": " 116/116 [00:00&lt;00:00, 9.84kB/s]"
          }
        },
        "74da3e694a8b405386545ae30d555155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac1db45b508046278e5a587bd7745ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f63ef372b246c3b3df56e4d17c11c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef95062ad5134531a6ef6b5acdeb3b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "584a3e9ccad748448856f7229afef4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "716b5676003d482fb25f957f5d4afdd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe2b83f7e084ee5a23089f832968a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b681e6d2c9fa4307bb4ea9eed6cfcd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85b2a5e765e24d8caf83e58c6e32eea5",
              "IPY_MODEL_d941f6b2aaf94ae281293cfad9694eef",
              "IPY_MODEL_d03b8f8fce9547f8a90d3c273b06b8c4"
            ],
            "layout": "IPY_MODEL_53dac2b2351a423a94846e602cc23abf"
          }
        },
        "85b2a5e765e24d8caf83e58c6e32eea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae32db4537e54e1b99c003d643b94095",
            "placeholder": "​",
            "style": "IPY_MODEL_f86c3dedd9254b22986b9f64741d8346",
            "value": "README.md: "
          }
        },
        "d941f6b2aaf94ae281293cfad9694eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e08e5d4611184c1aab9abc1bff84df1b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fd821786c124a37ab5ebc2723fd659b",
            "value": 1
          }
        },
        "d03b8f8fce9547f8a90d3c273b06b8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94c8b1a4d419485e9f32d9154f6e1a45",
            "placeholder": "​",
            "style": "IPY_MODEL_dc69b743ac6340aab3c4c187a3f3455d",
            "value": " 10.5k/? [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "53dac2b2351a423a94846e602cc23abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae32db4537e54e1b99c003d643b94095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86c3dedd9254b22986b9f64741d8346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e08e5d4611184c1aab9abc1bff84df1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8fd821786c124a37ab5ebc2723fd659b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94c8b1a4d419485e9f32d9154f6e1a45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc69b743ac6340aab3c4c187a3f3455d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f662aa8777404e22922a2eb02db2e898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4816f04b8e24efb9baa83951840dbef",
              "IPY_MODEL_1435f28568384c8bb10dc6a0ab26b0c8",
              "IPY_MODEL_38e95616e3f64248808835e642f44fab"
            ],
            "layout": "IPY_MODEL_b21189da329346e7a8a5c93f50145c94"
          }
        },
        "a4816f04b8e24efb9baa83951840dbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_320c7cffccf8444d803c07f4a2dfa75f",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7ffefb9f23493cb4636b820c949d80",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "1435f28568384c8bb10dc6a0ab26b0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53d02ab2582c4379ab7ad24c53599e48",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_454c76f4101d41e68fded64d8439820b",
            "value": 53
          }
        },
        "38e95616e3f64248808835e642f44fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c53f80c20a144b0a6a7be70cf1ef6ec",
            "placeholder": "​",
            "style": "IPY_MODEL_de3f2647d7514808913495e2e6480168",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.62kB/s]"
          }
        },
        "b21189da329346e7a8a5c93f50145c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "320c7cffccf8444d803c07f4a2dfa75f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7ffefb9f23493cb4636b820c949d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53d02ab2582c4379ab7ad24c53599e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "454c76f4101d41e68fded64d8439820b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c53f80c20a144b0a6a7be70cf1ef6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de3f2647d7514808913495e2e6480168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f73e34d3fd8f4a8198b840e2eee23cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b781c1b7e51d43678c3d922a37bdc2e3",
              "IPY_MODEL_a9023784b86448259d154c374db9fb4c",
              "IPY_MODEL_03b40c5dbb084e28944986c8fa309a3d"
            ],
            "layout": "IPY_MODEL_867840b4c11b41f1aae4827b39125119"
          }
        },
        "b781c1b7e51d43678c3d922a37bdc2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7c76cee4224100b4e05765c75ea1a3",
            "placeholder": "​",
            "style": "IPY_MODEL_50c2359884244e4f99ce60b8d8074876",
            "value": "config.json: 100%"
          }
        },
        "a9023784b86448259d154c374db9fb4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1e47d682b54368b9752d13d6418b4e",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5558b514a9d1418bbb4934920d88eadf",
            "value": 612
          }
        },
        "03b40c5dbb084e28944986c8fa309a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9213cb8ec374425281218bf18f2fff0d",
            "placeholder": "​",
            "style": "IPY_MODEL_2e0cb588b2be4e3da9be61eb2901424b",
            "value": " 612/612 [00:00&lt;00:00, 44.2kB/s]"
          }
        },
        "867840b4c11b41f1aae4827b39125119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7c76cee4224100b4e05765c75ea1a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c2359884244e4f99ce60b8d8074876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d1e47d682b54368b9752d13d6418b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5558b514a9d1418bbb4934920d88eadf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9213cb8ec374425281218bf18f2fff0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e0cb588b2be4e3da9be61eb2901424b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "962b5c561fb440a0943689b3e6ef13a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_076736027f444604be29586a577a6120",
              "IPY_MODEL_d22fbc337fa840da9502254afbff9aec",
              "IPY_MODEL_11465f15acdf43338d84b848cf2bf808"
            ],
            "layout": "IPY_MODEL_45d9acbab3f54ba896017b1686f62c50"
          }
        },
        "076736027f444604be29586a577a6120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e90094f76640a1b1242d883859eaa0",
            "placeholder": "​",
            "style": "IPY_MODEL_0fdaddab10064d19a4842a2bddf9b301",
            "value": "model.safetensors: 100%"
          }
        },
        "d22fbc337fa840da9502254afbff9aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a4b9575b83e4e3bb97e42c3ccace552",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f0c8521846d4529bd0d4a755d316932",
            "value": 90868376
          }
        },
        "11465f15acdf43338d84b848cf2bf808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43ebb0a586f4a32aed59d9c7206b4a5",
            "placeholder": "​",
            "style": "IPY_MODEL_e2ea24dae9744f49a30eea86255b8c97",
            "value": " 90.9M/90.9M [00:07&lt;00:00, 10.2MB/s]"
          }
        },
        "45d9acbab3f54ba896017b1686f62c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e90094f76640a1b1242d883859eaa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fdaddab10064d19a4842a2bddf9b301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a4b9575b83e4e3bb97e42c3ccace552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0c8521846d4529bd0d4a755d316932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d43ebb0a586f4a32aed59d9c7206b4a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ea24dae9744f49a30eea86255b8c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34429d5b7ce44215ab4af95264e16ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ced3875fa5d49e3b4845fd08effc449",
              "IPY_MODEL_a544939432af4b299e8fee7ad0bb7f15",
              "IPY_MODEL_1559a9ba00e449de9d85c715b95ccb13"
            ],
            "layout": "IPY_MODEL_6c395a23ba7a43f69a4bf0b9c10a75b0"
          }
        },
        "4ced3875fa5d49e3b4845fd08effc449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8b91f10bcc94d919825981283fe64d2",
            "placeholder": "​",
            "style": "IPY_MODEL_bb87d30e804a4caca059c6965fed971f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a544939432af4b299e8fee7ad0bb7f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eaf6b194ded4605860c63bc49b1a2c1",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5e93d837e216485ab31bc6f3985f9f67",
            "value": 350
          }
        },
        "1559a9ba00e449de9d85c715b95ccb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab864b0063e441359350b1506c57fc16",
            "placeholder": "​",
            "style": "IPY_MODEL_df257ec1cf584b41a8cca7d5ef9a6ae0",
            "value": " 350/350 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "6c395a23ba7a43f69a4bf0b9c10a75b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b91f10bcc94d919825981283fe64d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb87d30e804a4caca059c6965fed971f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0eaf6b194ded4605860c63bc49b1a2c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e93d837e216485ab31bc6f3985f9f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab864b0063e441359350b1506c57fc16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df257ec1cf584b41a8cca7d5ef9a6ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6b381b145a24e1aad92150c0afdf582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e56a196fa9884174ae1356ea01d479bf",
              "IPY_MODEL_acb5beaf03ea4143a8e9ef61ac2f036d",
              "IPY_MODEL_baab6c5156d542bfaf59e2892b90601c"
            ],
            "layout": "IPY_MODEL_434dd012e3904cd4ac9125f125913abf"
          }
        },
        "e56a196fa9884174ae1356ea01d479bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d15aa8ffffcb4aa881cf4f0233ae17ff",
            "placeholder": "​",
            "style": "IPY_MODEL_9e10a4f85a7d4e80aaabef080333cc70",
            "value": "vocab.txt: "
          }
        },
        "acb5beaf03ea4143a8e9ef61ac2f036d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b11638a17d451cb8c481e19c3c6adb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_001559959df6443888eb95655c519269",
            "value": 1
          }
        },
        "baab6c5156d542bfaf59e2892b90601c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_818fce7158154c9dbb4128b181ce6982",
            "placeholder": "​",
            "style": "IPY_MODEL_618dc3d70c064e42bd9b8d98507610c1",
            "value": " 232k/? [00:00&lt;00:00, 9.16MB/s]"
          }
        },
        "434dd012e3904cd4ac9125f125913abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d15aa8ffffcb4aa881cf4f0233ae17ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e10a4f85a7d4e80aaabef080333cc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b11638a17d451cb8c481e19c3c6adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "001559959df6443888eb95655c519269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "818fce7158154c9dbb4128b181ce6982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618dc3d70c064e42bd9b8d98507610c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e76928486744af4848469cf228ecbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73115b1d94e04bea825310017d06693d",
              "IPY_MODEL_6954e6c0da304ea98070b51ff11202ba",
              "IPY_MODEL_c39c6db80e8e439a97d208dab56bda60"
            ],
            "layout": "IPY_MODEL_52b088556281470fabf944394e18de0c"
          }
        },
        "73115b1d94e04bea825310017d06693d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a43b45e2f3ab4695aaa8e648f68f1e4f",
            "placeholder": "​",
            "style": "IPY_MODEL_f74a46dbf1964a10b17b350b5b8c1ff0",
            "value": "tokenizer.json: "
          }
        },
        "6954e6c0da304ea98070b51ff11202ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a588ae6a6f024e2a8b7cc46005437169",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70f01b7e7a42445e8eb0f24bd93e7f7f",
            "value": 1
          }
        },
        "c39c6db80e8e439a97d208dab56bda60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87768cc3f094ea598f05dc0a2454a4a",
            "placeholder": "​",
            "style": "IPY_MODEL_1cb3ab1177fc4eec9d9fb7ec7486d43d",
            "value": " 466k/? [00:00&lt;00:00, 20.8MB/s]"
          }
        },
        "52b088556281470fabf944394e18de0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43b45e2f3ab4695aaa8e648f68f1e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74a46dbf1964a10b17b350b5b8c1ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a588ae6a6f024e2a8b7cc46005437169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "70f01b7e7a42445e8eb0f24bd93e7f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c87768cc3f094ea598f05dc0a2454a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb3ab1177fc4eec9d9fb7ec7486d43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b9ca81a015b4a9f922ded00fc4651ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78433e56951e48378045388063e279b1",
              "IPY_MODEL_b3effa245c5a495f83edc3b60b8d45c7",
              "IPY_MODEL_a46d2c8116a140c3926cb1d31936581f"
            ],
            "layout": "IPY_MODEL_d0880598813641779adfe399bd480036"
          }
        },
        "78433e56951e48378045388063e279b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0bbf8e555f4bd3a98e2b4849e4f6c5",
            "placeholder": "​",
            "style": "IPY_MODEL_48af9a0b396f4d189e04b6193c90015a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b3effa245c5a495f83edc3b60b8d45c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea6081926f85401ea0e20a27c42b8b33",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_422b8ff121f24d6e8e82a0102a36db0c",
            "value": 112
          }
        },
        "a46d2c8116a140c3926cb1d31936581f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_237391bb84574d3881729bbcd7bc1da3",
            "placeholder": "​",
            "style": "IPY_MODEL_faf26c569407495cb453e9b25cb30538",
            "value": " 112/112 [00:00&lt;00:00, 11.0kB/s]"
          }
        },
        "d0880598813641779adfe399bd480036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c0bbf8e555f4bd3a98e2b4849e4f6c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48af9a0b396f4d189e04b6193c90015a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea6081926f85401ea0e20a27c42b8b33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "422b8ff121f24d6e8e82a0102a36db0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "237391bb84574d3881729bbcd7bc1da3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faf26c569407495cb453e9b25cb30538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee6d5d843fec4f609af1798810308f51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aae7e5c659774c569b49addffe90d0f2",
              "IPY_MODEL_bc5ba2e0cd474de4931bd6a8fb1802d6",
              "IPY_MODEL_2c9b7345adc547e39860d924c5181cc1"
            ],
            "layout": "IPY_MODEL_3ce53dc13a0b49fdac37e40e82cab95f"
          }
        },
        "aae7e5c659774c569b49addffe90d0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67739c7901dc4be8b9b3f79dab044121",
            "placeholder": "​",
            "style": "IPY_MODEL_cbcf678538e24456bc9396be20c83349",
            "value": "config.json: 100%"
          }
        },
        "bc5ba2e0cd474de4931bd6a8fb1802d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1755caebac499d9533ceb74d3a4f6f",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0f69ad164cb47d6b4b5fd808ce4985c",
            "value": 190
          }
        },
        "2c9b7345adc547e39860d924c5181cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ffb1f1a19944511b778aef6081604cc",
            "placeholder": "​",
            "style": "IPY_MODEL_ad4c3bd868394c309390e0906ade4e20",
            "value": " 190/190 [00:00&lt;00:00, 14.8kB/s]"
          }
        },
        "3ce53dc13a0b49fdac37e40e82cab95f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67739c7901dc4be8b9b3f79dab044121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcf678538e24456bc9396be20c83349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad1755caebac499d9533ceb74d3a4f6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f69ad164cb47d6b4b5fd808ce4985c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ffb1f1a19944511b778aef6081604cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4c3bd868394c309390e0906ade4e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}